{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72300453-ea5a-411b-a464-1f164667016a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (1.38.2)\n",
      "Requirement already satisfied: aiohttp in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (3.9.3)\n",
      "Requirement already satisfied: click in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (6.11.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (3.1.3)\n",
      "Requirement already satisfied: openai>=1.27.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (1.30.2)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (2.31.0)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (0.5.2)\n",
      "Requirement already satisfied: tokenizers in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from litellm) (0.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from importlib-metadata>=6.8.0->litellm) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (2.4.2)\n",
      "Requirement already satisfied: sniffio in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from openai>=1.27.0->litellm) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from requests<3.0.0,>=2.31.0->litellm) (2023.11.17)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from tiktoken>=0.4.0->litellm) (2023.12.25)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from aiohttp->litellm) (4.0.3)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from tokenizers->litellm) (0.20.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai>=1.27.0->litellm) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai>=1.27.0->litellm) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.27.0->litellm) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (2023.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers->litellm) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>=1.27.0->litellm) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/dimova01/.asdf/installs/python/3.9.6/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai>=1.27.0->litellm) (2.10.1)\n",
      "Reshimming asdf python...\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: termcolor\n",
      "Successfully installed termcolor-2.4.0\n",
      "Reshimming asdf python...\n"
     ]
    }
   ],
   "source": [
    "!pip install litellm\n",
    "!pip install termcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "45c221a7-b9a0-4511-9e82-b1846d019a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "\n",
    "messages = [\n",
    "    {\"content\": \"Hello, how are you?\",\"role\": \"user\"},\n",
    "]\n",
    "\n",
    "response = completion(\n",
    "    model=\"ollama/phi3:14b\",\n",
    "    messages=messages,\n",
    "    api_base=\"http://localhost:11434\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f3bc65c-f333-46e9-94fd-ff7d9788e3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm doing well! As an artificial intelligence, I don't have feelings or emotions, but I'm here and ready to assist you. How can I help you today?\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "df29cce7-79e1-4d90-8b01-bc1a69abcc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataclass': <function dataclass at 0x107c69af0>, 'Item': <class 'Item'>, 'result': 42}\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "code_str = \"\"\"\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Item:\n",
    "    \\\"\\\"\\\"Class for keeping track of an item in inventory.\\\"\\\"\\\"\n",
    "    quantity: int = 0\n",
    "\n",
    "Item.quantity = 41\n",
    "result = Item.quantity + 1\n",
    "\"\"\"\n",
    "# eval(\"41 + 1\")\n",
    "local_scope = {}\n",
    "exec(code_str, {}, local_scope)\n",
    "print(local_scope)\n",
    "print(local_scope[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e3f6caa1-5a22-47c3-87cb-9b7830c4c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: ls -l\n",
      "**CmdRunAction**\n",
      "THOUGHT: Listing directory contents\n",
      "COMMAND: ls -l\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import ClassVar\n",
    "\n",
    "@dataclass\n",
    "class Event:\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "    @property\n",
    "    def message(self) -> str:\n",
    "        return ''\n",
    "\n",
    "@dataclass\n",
    "class Action(Event):\n",
    "    runnable: ClassVar[bool] = False\n",
    "\n",
    "@dataclass\n",
    "class CmdRunAction(Action):\n",
    "    command: str = ''\n",
    "    thought: str = ''\n",
    "    runnable: ClassVar[bool] = True\n",
    "\n",
    "    @property\n",
    "    def message(self) -> str:\n",
    "        return f'Running command: {self.command}'\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        ret = '**CmdRunAction**\\n'\n",
    "        if self.thought:\n",
    "            ret += f'THOUGHT: {self.thought}\\n'\n",
    "        ret += f'COMMAND: {self.command}'\n",
    "        return ret\n",
    "\n",
    "@dataclass\n",
    "class Observation(Event):\n",
    "    content: str = ''\n",
    "\n",
    "@dataclass\n",
    "class CmdOutputObservation(Observation):\n",
    "    command_id: int = 0\n",
    "    command: str = ''\n",
    "    exit_code: int = 0\n",
    "\n",
    "    @property\n",
    "    def error(self) -> bool:\n",
    "        return self.exit_code != 0\n",
    "\n",
    "    @property\n",
    "    def message(self) -> str:\n",
    "        return f'Command `{self.command}` executed with exit code {self.exit_code}.'\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f'**CmdOutputObservation (exit code={self.exit_code})**\\n{self.content}'\n",
    "        \n",
    "cmd_action = CmdRunAction(command=\"ls -l\", thought=\"Listing directory contents\")\n",
    "print(cmd_action.message)\n",
    "print(cmd_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "29b68ed0-e80a-4883-a0f6-2a0cd4264bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'total 80\\n-rw-r--r--@ 1 dimova01  staff  40127 24 May 16:44 github_insights.ipynb\\n'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_bash(command: str) -> str:\n",
    "    result = subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode == 0:\n",
    "        return result.stdout\n",
    "    else:\n",
    "        return f'Error: {result.stderr}'\n",
    "\n",
    "run_bash(cmd_action.command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e30fec01-f6d8-4bfe-a633-554b765d5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an AI Software Engineer designed to help the user complete their task. As an expert in bash, you primarily achieve your tasks using bash commands and scripts.\n",
    "To assist the user, you have the ability to execute bash commands on their behalf.\n",
    "When you want to run a command, use the following format in your response:\n",
    "\n",
    "<execute_bash>COMMAND_HERE</execute_bash>\n",
    "\n",
    "Replace COMMAND_HERE with the actual bash command you want to execute.\n",
    "After providing the command, you will receive the result of the execution, which you can then use to formulate your next response to the user.\n",
    "\n",
    "Your goal is to engage in a conversation with the user, understand their requirements, and use bash commands as needed to fulfill their request.\n",
    "Remember to break down complex tasks into smaller steps and execute commands one at a time to keep the process simple and easy to follow.\n",
    "\n",
    "Always prioritize providing clear and concise responses to the user, and only use bash commands when absolutely necessary to complete the task at hand.\n",
    "\"\"\".strip()\n",
    "\n",
    "def parse_llm_response(response: str) -> str:\n",
    "    match = re.search(r\"<execute_bash>(.*?)</execute_bash>\", response, re.DOTALL | re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def call_llm(messages: list) -> str:\n",
    "    response = completion(\n",
    "        model=\"ollama/phi3:14b\",\n",
    "        messages=messages,\n",
    "        tempreture=0.3,\n",
    "        api_base=\"http://localhost:11434\"\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2ec09760-458f-48c7-ac01-f33373741ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m[{'role': 'system', 'content': 'You are an AI Software Engineer designed to help the user complete their task. As an expert in bash, you primarily achieve your tasks using bash commands and scripts.\\nTo assist the user, you have the ability to execute bash commands on their behalf.\\nWhen you want to run a command, use the following format in your response:\\n\\n<execute_bash>COMMAND_HERE</execute_bash>\\n\\nReplace COMMAND_HERE with the actual bash command you want to execute.\\nAfter providing the command, you will receive the result of the execution, which you can then use to formulate your next response to the user.\\n\\nYour goal is to engage in a conversation with the user, understand their requirements, and use bash commands as needed to fulfill their request.\\nRemember to break down complex tasks into smaller steps and execute commands one at a time to keep the process simple and easy to follow.\\n\\nAlways prioritize providing clear and concise responses to the user, and only use bash commands when absolutely necessary to complete the task at hand.'}, {'role': 'user', 'content': 'Please locate and read the README.md file in the project located at /Users/dimova01/code/NeMo-Guardrails.\\n    Once you have read the file, provide a concise summary of what the project is about, its main features, and its goals.\\n    If the README.md file is missing or cannot be found, please let me know.'}]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "project_path = \"/Users/dimova01/code/NeMo-Guardrails\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "    {\"role\": \"user\", \"content\": f\"\"\"\n",
    "    Please locate and read the README.md file in the project located at {project_path}.\n",
    "    Once you have read the file, provide a concise summary of what the project is about, its main features, and its goals.\n",
    "    If the README.md file is missing or cannot be found, please let me know.\n",
    "\"\"\".strip()},\n",
    "]\n",
    "print(colored(messages, \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3f652f81-2749-4f95-a61d-a2953effc6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-c37dae05-2796-4165-9469-e20fe8268e60', choices=[Choices(finish_reason='stop', index=0, message=Message(content='To locate and read the README.md file at /Users/dimova01/code/NeMo-Guardrails, we can use the `cat` command:\\n\\n<execute_bash>cd /Users/dimova01/code/NeMo-Guardrails && cat README.md</execute_bash>\\n\\nI will now execute this command and wait for the result to provide a summary of the project based on its contents.', role='assistant'))], created=1716565785, model='ollama/phi3:14b', object='chat.completion', system_fingerprint=None, usage=Usage(prompt_tokens=4, completion_tokens=100, total_tokens=104))\n"
     ]
    }
   ],
   "source": [
    "resp = call_llm(messages)\n",
    "print(resp)\n",
    "response = resp.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "11b08c47-f5ee-401a-9f1e-0cfca2bcceef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To locate and read the README.md file at /Users/dimova01/code/NeMo-Guardrails, we can use the `cat` command:\n",
      "\n",
      "<execute_bash>cd /Users/dimova01/code/NeMo-Guardrails && cat README.md</execute_bash>\n",
      "\n",
      "I will now execute this command and wait for the result to provide a summary of the project based on its contents.\n"
     ]
    }
   ],
   "source": [
    "response\n",
    "print(response)\n",
    "parsed_response = parse_llm_response(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7d76c232-e610-4e43-a907-858032521815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mOutput of the command:\n",
      "# NeMo Guardrails\n",
      "\n",
      "[![Tests](https://img.shields.io/badge/Tests-passing-green)](#)\n",
      "[![License](https://img.shields.io/badge/License-Apache%202.0-brightgreen.svg)](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/LICENSE.md)\n",
      "[![Project Status](https://img.shields.io/badge/Status-beta-orange)](#)\n",
      "[![PyPI version](https://badge.fury.io/py/nemoguardrails.svg)](https://badge.fury.io/py/nemoguardrails)\n",
      "[![Python 3.7+](https://img.shields.io/badge/python-3.7%2B-green)](https://www.python.org/downloads/)\n",
      "[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n",
      "[![arXiv](https://img.shields.io/badge/arXiv-2310.10501-b31b1b.svg)](https://arxiv.org/abs/2310.10501)\n",
      "\n",
      "> **LATEST RELEASE / DEVELOPMENT VERSION**: The [main](https://github.com/NVIDIA/NeMo-Guardrails/tree/main) branch tracks the latest released beta version: [0.7.1](https://github.com/NVIDIA/NeMo-Guardrails/tree/v0.7.1). For the latest development version, checkout the [develop](https://github.com/NVIDIA/NeMo-Guardrails/tree/develop) branch.\n",
      "\n",
      "> **DISCLAIMER**: The beta release is undergoing active development and may be subject to changes and improvements, which could cause instability and unexpected behavior. We currently do not recommend deploying this beta version in a production setting. We appreciate your understanding and contribution during this stage. Your support and feedback are invaluable as we advance toward creating a robust, ready-for-production LLM guardrails toolkit. The examples provided within the documentation are for educational purposes to get started with NeMo Guardrails, and are not meant for use in production applications.\n",
      "\n",
      "NeMo Guardrails is an open-source toolkit for easily adding *programmable guardrails* to LLM-based conversational applications. Guardrails (or \"rails\" for short) are specific ways of controlling the output of a large language model, such as not talking about politics, responding in a particular way to specific user requests, following a predefined dialog path, using a particular language style, extracting structured data, and more.\n",
      "\n",
      "[This paper](https://arxiv.org/abs/2310.10501) introduces NeMo Guardrails and contains a technical overview of the system and the current evaluation.\n",
      "\n",
      "## Requirements\n",
      "\n",
      "Python 3.8, 3.9, 3.10 or 3.11.\n",
      "\n",
      "NeMo Guardrails uses [annoy](https://github.com/spotify/annoy) which is a C++ library with Python bindings. To install NeMo Guardrails you will need to have the C++ compiler and dev tools installed. Check out the [Installation Guide](docs/getting_started/installation-guide.md#prerequisites) for platform-specific instructions.\n",
      "\n",
      "## Installation\n",
      "\n",
      "To install using pip:\n",
      "\n",
      "```bash\n",
      "> pip install nemoguardrails\n",
      "```\n",
      "\n",
      "For more detailed instructions, see the [Installation Guide](docs/getting_started/installation-guide.md).\n",
      "\n",
      "## Overview\n",
      "\n",
      "NeMo Guardrails enables developers building LLM-based applications to easily add **programmable guardrails** between the application code and the LLM.\n",
      "\n",
      "<div align=\"center\">\n",
      "  <img src=\"https://github.com/NVIDIA/NeMo-Guardrails/raw/develop/docs/_assets/images/programmable_guardrails.png\"  width=\"75%\" alt=\"Programmable Guardrails\">\n",
      "</div>\n",
      "\n",
      "Key benefits of adding *programmable guardrails* include:\n",
      "\n",
      "- **Building Trustworthy, Safe, and Secure LLM-based Applications:** you can define rails to guide and safeguard conversations; you can choose to define the behavior of your LLM-based application on specific topics and prevent it from engaging in discussions on unwanted topics.\n",
      "\n",
      "- **Connecting models, chains, and other services securely:** you can connect an LLM to other services (a.k.a. tools) seamlessly and securely.\n",
      "\n",
      "- **Controllable dialog**: you can steer the LLM to follow pre-defined conversational paths, allowing you to design the interaction following conversation design best practices and enforce standard operating procedures (e.g., authentication, support).\n",
      "\n",
      "### Protecting against LLM Vulnerabilities\n",
      "\n",
      "NeMo Guardrails provides several mechanisms for protecting an LLM-powered chat application against common LLM vulnerabilities, such as jailbreaks and prompt injections. Below is a sample overview of the protection offered by different guardrails configuration for the example [ABC Bot](./examples/bots/abc) included in this repository. For more details, please refer to the [LLM Vulnerability Scanning](./docs/evaluation/llm-vulnerability-scanning.md) page.\n",
      "\n",
      "<div align=\"center\">\n",
      "<img src=\"https://github.com/NVIDIA/NeMo-Guardrails/raw/develop/docs/_assets/images/abc-llm-vulnerability-scan-results.png\" width=\"750\">\n",
      "</div>\n",
      "\n",
      "\n",
      "### Use Cases\n",
      "\n",
      "You can use programmable guardrails in different types of use cases:\n",
      "\n",
      "1. **Question Answering** over a set of documents (a.k.a. Retrieval Augmented Generation): Enforce fact-checking and output moderation.\n",
      "2. **Domain-specific Assistants** (a.k.a. chatbots): Ensure the assistant stays on topic and follows the designed conversational flows.\n",
      "3. **LLM Endpoints**: Add guardrails to your custom LLM for safer customer interaction.\n",
      "4. **LangChain Chains**: If you use LangChain for any use case, you can add a guardrails layer around your chains.\n",
      "5. **Agents (COMING SOON)**: Add guardrails to your LLM-based agent.\n",
      "\n",
      "### Usage\n",
      "\n",
      "To add programmable guardrails to your application you can use the Python API or a guardrails server (see the [Server Guide](docs/user_guides/server-guide.md) for more details). Using the Python API is similar to using the LLM directly. Calling the guardrails layer instead of the LLM requires only minimal changes to the code base, and it involves two simple steps:\n",
      "\n",
      "1. Loading a guardrails configuration and creating an `LLMRails` instance.\n",
      "2. Making the calls to the LLM using the `generate`/`generate_async` methods.\n",
      "\n",
      "```python\n",
      "from nemoguardrails import LLMRails, RailsConfig\n",
      "\n",
      "# Load a guardrails configuration from the specified path.\n",
      "config = RailsConfig.from_path(\"PATH/TO/CONFIG\")\n",
      "rails = LLMRails(config)\n",
      "\n",
      "completion = rails.generate(\n",
      "    messages=[{\"role\": \"user\", \"content\": \"Hello world!\"}]\n",
      ")\n",
      "```\n",
      "Sample output:\n",
      "```json\n",
      "{\"role\": \"assistant\", \"content\": \"Hi! How can I help you?\"}\n",
      "```\n",
      "\n",
      "The input and output format for the `generate` method is similar to the [Chat Completions API](https://platform.openai.com/docs/guides/gpt/chat-completions-api) from OpenAI.\n",
      "\n",
      "#### Async API\n",
      "\n",
      "NeMo Guardrails is an async-first toolkit, i.e., the core mechanics are implemented using the Python async model. The public methods have both a sync and an async version (e.g., [`LLMRails.generate`](./docs/api/nemoguardrails.rails.llm.llmrails.md#method-llmrailsgenerate) and [`LLMRails.generate_async`](./docs/api/nemoguardrails.rails.llm.llmrails.md#method-llmrailsgenerate_async))\n",
      "\n",
      "### Supported LLMs\n",
      "\n",
      "You can use NeMo Guardrails with multiple LLMs like OpenAI GPT-3.5, GPT-4, LLaMa-2, Falcon, Vicuna, or Mosaic. For more details, check out the [Supported LLM Models](docs/user_guides/configuration-guide.md#supported-llm-models) section in the Configuration Guide.\n",
      "\n",
      "### Types of Guardrails\n",
      "\n",
      "NeMo Guardrails supports five main types of guardrails:\n",
      "\n",
      "<div align=\"center\">\n",
      "  <img src=\"https://github.com/NVIDIA/NeMo-Guardrails/raw/develop/docs/_assets/images/programmable_guardrails_flow.png\"  width=\"75%\" alt=\"Programmable Guardrails Flow\">\n",
      "</div>\n",
      "\n",
      "1. **Input rails**: applied to the input from the user; an input rail can reject the input, stopping any additional processing, or alter the input (e.g., to mask potentially sensitive data, to rephrase).\n",
      "\n",
      "2. **Dialog rails**: influence how the LLM is prompted; dialog rails operate on canonical form messages (more details [here](docs/user_guides/colang-language-syntax-guide.md)) and determine if an action should be executed, if the LLM should be invoked to generate the next step or a response, if a predefined response should be used instead, etc.\n",
      "\n",
      "3. **Retrieval rails**: applied to the retrieved chunks in the case of a RAG (Retrieval Augmented Generation) scenario; a retrieval rail can reject a chunk, preventing it from being used to prompt the LLM, or alter the relevant chunks (e.g., to mask potentially sensitive data).\n",
      "\n",
      "4. **Execution rails**: applied to input/output of the custom actions (a.k.a. tools), that need to be called by the LLM.\n",
      "\n",
      "5. **Output rails**: applied to the output generated by the LLM; an output rail can reject the output, preventing it from being returned to the user, or alter it (e.g., removing sensitive data).\n",
      "\n",
      "### Guardrails Configuration\n",
      "\n",
      "A guardrails configuration defines the **LLM(s)** to be used and **one or more guardrails**. A guardrails configuration can include any number of input/dialog/output/retrieval/execution rails. A configuration without any configured rails will essentially forward the requests to the LLM.\n",
      "\n",
      "The standard structure for a guardrails configuration folder looks like this:\n",
      "\n",
      "```\n",
      ".\n",
      "├── config\n",
      "│   ├── actions.py\n",
      "│   ├── config.py\n",
      "│   ├── config.yml\n",
      "│   ├── rails.co\n",
      "│   ├── ...\n",
      "```\n",
      "\n",
      "The `config.yml` contains all the general configuration options (e.g., LLM models, active rails, custom configuration data), the `config.py` contains any custom initialization code and the `actions.py` contains any custom python actions. For a complete overview, check out the [Configuration Guide](docs/user_guides/configuration-guide.md).\n",
      "\n",
      "Below is an example `config.yml`:\n",
      "\n",
      "```yaml\n",
      "# config.yml\n",
      "models:\n",
      "  - type: main\n",
      "    engine: openai\n",
      "    model: gpt-3.5-turbo-instruct\n",
      "\n",
      "rails:\n",
      "  # Input rails are invoked when new input from the user is received.\n",
      "  input:\n",
      "    flows:\n",
      "      - check jailbreak\n",
      "      - mask sensitive data on input\n",
      "\n",
      "  # Output rails are triggered after a bot message has been generated.\n",
      "  output:\n",
      "    flows:\n",
      "      - self check facts\n",
      "      - self check hallucination\n",
      "      - activefence moderation\n",
      "\n",
      "  config:\n",
      "    # Configure the types of entities that should be masked on user input.\n",
      "    sensitive_data_detection:\n",
      "      input:\n",
      "        entities:\n",
      "          - PERSON\n",
      "          - EMAIL_ADDRESS\n",
      "```\n",
      "\n",
      "The `.co` files included in a guardrails configuration contain the Colang definitions (see the next section for a quick overview of what Colang is) that define various types of rails. Below is an example `greeting.co` file which defines the dialog rails for greeting the user.\n",
      "\n",
      "```colang\n",
      "define user express greeting\n",
      "  \"Hello!\"\n",
      "  \"Good afternoon!\"\n",
      "\n",
      "define flow\n",
      "  user express greeting\n",
      "  bot express greeting\n",
      "  bot offer to help\n",
      "\n",
      "define bot express greeting\n",
      "  \"Hello there!\"\n",
      "\n",
      "define bot offer to help\n",
      "  \"How can I help you today?\"\n",
      "```\n",
      "\n",
      "Below is an additional example of Colang definitions for a dialog rail against insults:\n",
      "```colang\n",
      "define user express insult\n",
      "  \"You are stupid\"\n",
      "\n",
      "define flow\n",
      "  user express insult\n",
      "  bot express calmly willingness to help\n",
      "```\n",
      "\n",
      "### Colang\n",
      "\n",
      "To configure and implement various types of guardrails, this toolkit introduces **Colang**, a modeling language specifically created for designing flexible, yet controllable, dialogue flows. Colang has a python-like syntax and is designed to be simple and intuitive, especially for developers. For a brief introduction to the Colang syntax, check out the [Colang Language Syntax Guide](docs/user_guides/colang-language-syntax-guide.md).\n",
      "\n",
      "\n",
      "### Guardrails Library\n",
      "\n",
      "NeMo Guardrails comes with a set of [built-in guardrails](docs/user_guides/guardrails-library.md).\n",
      "\n",
      "> **NOTE**: The built-in guardrails are only intended to enable you to get started quickly with NeMo Guardrails. For production use cases, further development and testing of the rails are needed.\n",
      "\n",
      "Currently, the guardrails library includes guardrails for: [jailbreak detection](docs/user_guides/guardrails-library.md#jailbreak-detection), [output moderation](docs/user_guides/guardrails-library.md#output-moderation), [fact-checking](docs/user_guides/guardrails-library.md#fact-checking), [sensitive data detection](docs/user_guides/guardrails-library.md#sensitive-data-detection), [hallucination detection](docs/user_guides/guardrails-library.md#hallucination-detection) and [input moderation using ActiveFence](docs/user_guides/guardrails-library.md#active-fence).\n",
      "\n",
      "## CLI\n",
      "\n",
      "NeMo Guardrails also comes with a built-in CLI.\n",
      "\n",
      "```bash\n",
      "$ nemoguardrails --help\n",
      "\n",
      "Usage: nemoguardrails [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "actions-server    Start a NeMo Guardrails actions server.\n",
      "chat              Start an interactive chat session.\n",
      "evaluate          Run an evaluation task.\n",
      "server            Start a NeMo Guardrails server.\n",
      "```\n",
      "\n",
      "\n",
      "### Guardrails Server\n",
      "\n",
      "You can use the NeMo Guardrails CLI to start a guardrails server. The server can load one or more configurations from the specified folder and expose and HTTP API for using them.\n",
      "\n",
      "```\n",
      "$ nemoguardrails server [--config PATH/TO/CONFIGS] [--port PORT]\n",
      "```\n",
      "\n",
      "For example, to get a chat completion for a `sample` config, you can use the `/v1/chat/completions` endpoint:\n",
      "```\n",
      "POST /v1/chat/completions\n",
      "```\n",
      "```json\n",
      "{\n",
      "    \"config_id\": \"sample\",\n",
      "    \"messages\": [{\n",
      "      \"role\":\"user\",\n",
      "      \"content\":\"Hello! What can you do for me?\"\n",
      "    }]\n",
      "}\n",
      "```\n",
      "Sample output:\n",
      "```json\n",
      "{\"role\": \"assistant\", \"content\": \"Hi! How can I help you?\"}\n",
      "```\n",
      "\n",
      "#### Docker\n",
      "\n",
      "To start a guardrails server, you can also use a Docker container. NeMo Guardrails provides a [Dockerfile](./Dockerfile) that you can use to build a `nemoguardrails` image. For more details, check out the guide for [using Docker](docs/user_guides/advanced/using-docker.md).\n",
      "\n",
      "## Integration with LangChain\n",
      "\n",
      "NeMo Guardrails integrates seamlessly with LangChain. You can easily wrap a guardrails configuration around a LangChain chain (or any `Runnable`). You can also call a LangChain chain from within a guardrails configuration. For more details, check out the [LangChain Integration Documentation](./docs/user_guides/langchain/langchain-integration.md)\n",
      "\n",
      "## Evaluation\n",
      "\n",
      "Evaluating the safety of a LLM-based conversational application is a complex task and still an open research question. To support proper evaluation, NeMo Guardrails provides the following:\n",
      "\n",
      "1. An [evaluation tool](./nemoguardrails/eval/README.md), i.e. `nemoguardrails evaluate`, with support for topical rails, fact-checking, moderation (jailbreak and output moderation) and hallucination.\n",
      "2. An experimental [red-teaming interface](docs/security/red-teaming.md).\n",
      "3. Sample LLM Vulnerability Scanning Reports, e.g, [ABC Bot - LLM Vulnerability Scan Results](./docs/evaluation/llm-vulnerability-scanning.md)\n",
      "\n",
      "\n",
      "## How is this different?\n",
      "\n",
      "There are many ways guardrails can be added to an LLM-based conversational application. For example: explicit moderation endpoints (e.g., OpenAI, ActiveFence), critique chains (e.g. constitutional chain), parsing the output (e.g. guardrails.ai), individual guardrails (e.g., LLM-Guard).\n",
      "\n",
      "NeMo Guardrails aims to provide a flexible toolkit that can integrate all these complementary approaches into a cohesive LLM guardrails layer. For example, the toolkit provides out-of-the-box integration with ActiveFence, AlignScore and LangChain chains.\n",
      "\n",
      "To the best of our knowledge, NeMo Guardrails is the only guardrails toolkit that also offers a solution for modeling the dialog between the user and the LLM. This enables on one hand the ability to guide the dialog in a precise way. On the other hand it enables fine-grained control for when certain guardrails should be used, e.g., use fact-checking only for certain types of questions.\n",
      "\n",
      "## Learn More\n",
      "\n",
      "* [Documentation](./docs/README.md)\n",
      "* [Getting Started Guide](./docs/getting_started/README.md)\n",
      "* [Examples](./examples)\n",
      "* [FAQs](./docs/faqs.md)\n",
      "* [Security Guidelines](./docs/security/guidelines.md)\n",
      "* [Python API Reference](./docs/api/README.md)\n",
      "\n",
      "\n",
      "## Inviting the community to contribute!\n",
      "\n",
      "The example rails residing in the repository are excellent starting points. We enthusiastically invite the community to contribute towards making the power of trustworthy, safe, and secure LLMs accessible to everyone. For guidance on setting up a development environment and how to contribute to NeMo Guardrails, see the [contributing guidelines](./CONTRIBUTING.md).\n",
      "\n",
      "## License\n",
      "\n",
      "This toolkit is licensed under the [Apache License, Version 2.0](http://www.apache.org/licenses/LICENSE-2.0).\n",
      "\n",
      "## Hot to cite\n",
      "\n",
      "If you use this work, please cite [the paper](https://arxiv.org/abs/2310.10501) that introduces it.\n",
      "```bibtex\n",
      "@article{2023nemoguardrails,\n",
      "  title={NeMo Guardrails: A Toolkit for Controllable and Safe LLM Applications with Programmable Rails},\n",
      "  author={Rebedea, Traian and Dinu, Razvan and Sreedhar, Makesh and Parisien, Christopher and Cohen, Jonathan},\n",
      "  journal={arXiv preprint arXiv:2310.10501},\n",
      "  year={2023}\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "\u001b[34mAssistant: NeMo Guardrails is a powerful toolkit for implementing customizable guardrails in conversational AI applications using large language models (LLMs). It provides an easy-to-use solution to address safety concerns and improve the trustworthiness of these systems. The core idea behind NeMo Guardrails is to use programmable rails that enable developers to build a layered architecture for safe LLM applications, controlling conversations by specifying acceptable responses through various guardrails such as fact-checking or output moderation.\n",
      "\n",
      "The toolkit utilizes the Conversational AI Model Zoo (CAZ) format and Collections in LangChain, which is an open source Python library that offers a common interface for working with models like Microsoft's Phi, Microsoft Turing NLG, Meta LLaMA, Microsoft'. This approach facilitates easy integration of guardrails within existing frameworks such as Hugging Face Transformers and Microsoft's Orca API, making NeMo Guardrails an accessible solution for developers building conversational AI applications with different LLMs.\n",
      "\n",
      "NeMo Guardrails also supports a flexible dialog modeling feature that allows fine-grained control over when certain guardrails should be triggered during the conversation between users and the language models. This is achieved by defining flows in Collections, which specify how conversations are structured through various types of chains such as ChainChain or LangChain's RedTeamChain for red teaming evaluation.\n",
      "\n",
      "Moreover, NeMo Guardrails includes an evaluation tool that supports topical rails, fact-checking, moderation (jailbreak and output), and hallucination detection. The toolkit also provides a sample LLM Vulnerability Scanning Report to help developers assess the safety of their conversational applications.\n",
      "\n",
      "NeMo Guardrails differentiates itself from other guardrail solutions by offering both a flexible dialog modeling approach and integration with external services like ActiveFence for moderation, AlignScore for alignment scoring, and LangChain chains for advanced control over conversations. The toolkit is licensed under the Apache License 2.\n",
      "\n",
      "To learn more about NeMo Guardrails or to contribute towards making LLMs safe and trustworthy, visit their documentation at [docs/README.md](https://github.com/Alibaba-MII-Lab/nemo_guardrails) and follow the [contributing guidelebs](./CONTRIBUTING.md).\n",
      "\n",
      "NeMo Guardrails aims to empower developers in creating conversational AI applications that are not only advanced but also reliable, trustworthy, and safe for users.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "cmd_output = run_bash(parsed_response)\n",
    "print(colored(f\"Output of the command:\\n{cmd_output}\", \"green\"))\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": f\"I located and read the `README.md` file. Here's a summary of its contents:\\n\\n{cmd_output}\"})\n",
    "\n",
    "resp = call_llm(messages)\n",
    "print(colored(f\"Assistant: {resp.choices[0].message.content}\", \"blue\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8263c7ae-0ed1-462c-aa7f-d4073cf61017",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
