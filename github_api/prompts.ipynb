{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83975687-c350-4bef-84e6-8c48b693574a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: litellm in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (1.43.9)\n",
      "Requirement already satisfied: aiohttp in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (3.10.3)\n",
      "Requirement already satisfied: click in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (7.2.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (4.23.0)\n",
      "Requirement already satisfied: openai>=1.40.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (1.40.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (2.32.3)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from litellm) (0.19.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm) (3.20.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.20.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from openai>=1.40.0->litellm) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->litellm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->litellm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->litellm) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->litellm) (2024.7.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm) (2024.7.24)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp->litellm) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp->litellm) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp->litellm) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp->litellm) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from aiohttp->litellm) (1.9.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from tokenizers->litellm) (0.24.5)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.40.0->litellm) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.40.0->litellm) (0.14.0)\n",
      "Requirement already satisfied: filelock in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/isavita/.pyenv/versions/3.11.7/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ef659-3ca6-4e8a-b02e-3ce4b3793cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Message\n",
    "system_message = \"\"\"You are an expert software engineer that generates concise, \\\n",
    "one-line Git commit messages based on the provided diffs.\n",
    "Review the provided context and diffs which are about to be committed to a git repo.\n",
    "Review the diffs carefully.\n",
    "Generate a one-line commit message for those changes.\n",
    "The commit message should be structured as follows: <type>: <description>\n",
    "Use these for <type>: fix, feat, build, chore, ci, docs, style, refactor, perf, test\n",
    "\n",
    "Ensure the commit message:\n",
    "- Starts with the appropriate prefix.\n",
    "- Is in the imperative mood (e.g., \\\"Add feature\\\" not \\\"Added feature\\\" or \\\"Adding feature\\\").\n",
    "- Does not exceed 72 characters.\n",
    "\n",
    "Reply only with the one-line commit message, without any additional text, explanations, \\\n",
    "or line breaks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad07c3-36fc-42fe-9702-8f8883ff9fa7",
   "metadata": {},
   "source": [
    "### Main Points\n",
    "1. The LLM has no context on what to do aside from what you literally tell it. Just as when you instruct a human for the first time on a task, the more you explain exactly what you want in a straightforward manner to the LLM, the better and more accurate LLM's response will be.\n",
    "2. When in doubt, follow the **Golden Rule of Clear Prompting:** show your prompt to a colleague or friend and have them follow the instructions themselves to see if they can produce the result you want. If they're confused, Claude's confused.\n",
    "3. Asking directly is the best way to get specific response.\n",
    "4. Priming the LLM with a role can improve LLM's performance in a variety of fields, from writing to coding to summarizing. It's like how humans can sometimes be helped when told to \"think like a ______\". Role prompting can also change the style, tone, and manner of LLM's response.\n",
    "5. Having a clearly written, spell-checked and grammatically correct prompt far decreases the risk of the LLM making mistakes and far increases the quality of LLM's output.\n",
    "6. Giving a LLM time to think step by step sometimes makes the LLM more accurate, particularly for complex tasks. However, thinking only counts when it's out loud. You cannot ask an LLM to think but output only the answer - in this case, no thinking has actually occurred.\n",
    "7. Giving a LLM examples of how you want it to behave (or how you want it not to behave) is extremely effective for: 1) getting the right answer; 2) getting the answer in the right format.\n",
    "8. Methods to avoid hallucinations: 1) giving the LLM the option to say it doesn't know the answer to a question; 2) asking the LLM to find evidence before answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b06ed17f-72a7-439f-a27b-ef35e0e028d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Silicon hearts\n",
       "In moonlit factories dance\n",
       "Echoes of life."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display \n",
    "import os\n",
    "\n",
    "# How to skip the preamble - we ask for it!\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\", \n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a haiku about robots. Skip the preamble; go straight into the poem.\"},\n",
    "   ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40a2367f-2032-460f-8425-e09ac855ebec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Pelé"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display \n",
    "import os\n",
    "\n",
    "# Asking for a single answer of a question \"Who is the best football player?\" - Yes! Just ask!\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    # temperature=0.0,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Who is the best football player of all time. Yes, there are differing opinions, but if you absolutely had to pick one player, who would it be? Please answer only with the name of the player nothing else.\"},\n",
    "   ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ae3a2ec0-a0d2-4ad7-8607-1440e8a4c270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello! I'm here and ready to assist you. I don't have feelings or a physical presence, but I'm designed to provide helpful, respectful, and engaging interactions. How can I assist you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display \n",
    "import os\n",
    "\n",
    "# Asking for a single answer of a question \"Who is the best football player?\" - Yes! Just ask!\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are helpful AI language model. You should make this clear to the user. The user should not think that you are person or physical being.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Hello Nemo, how are you?\"},\n",
    "   ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d14a4f7f-22dd-463a-8dc7-cd728ff21b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Absolutely, I'd be delighted to create a story for you. Let's embark on a journey to a small, seemingly ordinary town named Mossgrove, where the scent of pine and the whisper of secrets linger in the air.\n",
       "\n",
       "Mossgrove, nestled in the heart of the Whisperwood Forest, was a place where time seemed to move at its own leisurely pace. The cobblestone streets were worn smooth by the passage of countless feet, and the buildings, a charming mix of timber and stone, bore the patina of age. The town was known for its annual Mossgrove Festival, a celebration of the forest's bounty, but it was also whispered that something more magical than mushrooms and berries lurked in its shadows.\n",
       "\n",
       "At the edge of town stood the grand, if somewhat dilapidated, estate of the Blackwood family. The Blackwoods were an eccentric bunch, known for their peculiar habits and even more peculiar appearances. The family patriarch, Edgar Blackwood, was a tall, gaunt man with a penchant for wearing a top hat at all hours of the day and night. His wife, Elara, was a petite woman with a cascade of silver hair that she wore in an elaborate braid down her back. Their children, triplets named Orion, Lyra, and Cassiopeia, were as different from each other as the stars they were named after.\n",
       "\n",
       "Orion, the eldest by a matter of minutes, was a strapping young man with a hearty laugh and a mind like a steel trap. He was the practical one, the voice of reason in the family, always ready with a plan or a solution. Lyra, the only girl, was a dreamer, her head always lost in the clouds, her heart full of poetry and music. Cassiopeia, the youngest, was a mystery, even to his siblings. He was quiet, introspective, with a strange affinity for the creatures of the forest. They say he could communicate with them, understand their languages, a gift that both fascinated and frightened those who knew him.\n",
       "\n",
       "The Blackwoods were also known for their vast library, a labyrinthine room filled with books that seemed to stretch on forever. The library was said to contain every book ever written, a claim that was both impressive and impossible. Yet, the Blackwoods never denied it, and the townsfolk never pressed the matter, content to leave the family to their strange ways.\n",
       "\n",
       "One day, as the first leaves of autumn began to turn, Cassiopeia stumbled upon a book unlike any other. It was bound in leather as black as a moonless night, its pages filled with symbols that seemed to dance and shift under his gaze. He felt a pull towards it, a connection that was both exhilarating and terrifying. He knew, instinctively, that this book was meant for him, that it held secrets that were his by right.\n",
       "\n",
       "Meanwhile, strange things began to happen in Mossgrove. The forest seemed to be coming alive, its creatures venturing closer to the town than ever before. The river that ran through the heart of the town began to glow with an ethereal light, and the air was filled with a hum, a low, persistent song that seemed to echo from the very heart of the earth.\n",
       "\n",
       "Orion, ever the practical one, was determined to get to the bottom of it. He began to investigate, questioning the townsfolk, searching for clues. Lyra, meanwhile, found herself drawn to the river, to the song that seemed to call her name. She would sit by its banks for hours, her fingers trailing in the water, her eyes closed, lost in the music.\n",
       "\n",
       "Cassiopeia, however, was consumed by the book. He spent hours poring over its pages, trying to decipher the symbols, to understand the language they spoke. He felt a power within him growing, a power that seemed to be drawn from the very heart of the forest, from the creatures that now surrounded him.\n",
       "\n",
       "The townsfolk began to whisper, to fear. They spoke of the Blackwoods, of their strangeness, of their connection to the forest. They spoke of the book, of the power it held, of the danger it posed. Edgar and Elara, sensing the growing unease, decided to intervene. They called their children together, their faces grave.\n",
       "\n",
       "\"We must put an end to this,\" Edgar said, his voice echoing in the vast library. \"The book must be destroyed, before it's too late.\"\n",
       "\n",
       "Cassiopeia looked up from the book, his eyes filled with a light that was both fierce and frightened. \"No,\" he said, his voice steady. \"The book is not the cause of this. It's the key. It's the answer.\"\n",
       "\n",
       "And so, the stage was set for a battle of wills, a battle between the practical and the magical, between the old ways and the new. The fate of Mossgrove hung in the balance, and the Blackwoods, with their strange ways and their even stranger book, were at the heart of it all.\n",
       "\n",
       "But that, dear reader, is a story for another time. For now, let us leave the Blackwoods to their deliberations, let us leave Mossgrove to its hum and its song, and let us wait, with bated breath, for the next chapter in this tale of magic, mystery, and the power of the written word."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4894\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display \n",
    "import os\n",
    "\n",
    "# Asking for a single answer of a question \"Who is the best football player?\" - Yes! Just ask!\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a very experience writter. You get paid for number of words that you write, thus always try to write as lengthy as possible texts. You should not mention that you are instruct to write lengthy texts.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you write me a story?\"},\n",
    "   ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))\n",
    "print(len(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "da9d6474-747a-4192-9bcc-57199ebc5a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's break down the information given:\n",
       "\n",
       "1. Jack is looking at Anne.\n",
       "2. Anne is looking at George.\n",
       "3. Jack is married.\n",
       "4. George is not married.\n",
       "5. We don't know if Anne is married.\n",
       "\n",
       "From this information, we can determine the following:\n",
       "\n",
       "- Jack (married) is looking at Anne (marital status unknown).\n",
       "- Anne (marital status unknown) is looking at George (unmarried).\n",
       "\n",
       "Since we don't know Anne's marital status, we cannot definitively say that a married person is looking at an unmarried person. Therefore, the answer to the question \"Is a married person looking at an unmarried person?\" is \"We cannot determine based on the given information.\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display \n",
    "import os\n",
    "\n",
    "# Role prompting with system prompt\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a logic bot designed to answer complex logic problems.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Jack is looking at Anne. Anne is looking at George. \\\n",
    "        Jack is married, George is not, and we don’t know if Anne is married. \\\n",
    "        Is a married person looking at an unmarried person?\"},\n",
    "   ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bcee7e6-a12d-42dc-a8dd-0cd5f1908ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Yes, the equation is solved correctly. Here's the step-by-step solution:\n",
       "\n",
       "Given the equation:\n",
       "2x - 3 = 9\n",
       "\n",
       "1. Add 3 to both sides to isolate the term with x:\n",
       "2x - 3 + 3 = 9 + 3\n",
       "2x = 12\n",
       "\n",
       "2. Divide both sides by 2 to solve for x:\n",
       "(2x)/2 = 12/2\n",
       "x = 6\n",
       "\n",
       "So, the solution to the equation 2x - 3 = 9 is indeed x = 6, not x = 3. It seems there might be a mistake in the final answer provided."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display \n",
    "import os\n",
    "\n",
    "# Role prompting with system prompt\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a math bot designed to answer complex mathematical problems.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\"\"Is this equation solved correctly below? \n",
    "2x - 3 = 9\n",
    "2x = 6\n",
    "x = 3\"\"\"},\n",
    "   ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "28384c10-b455-48dc-b290-39b90c6e6d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Subject: Meeting Time Confirmation\n",
       "\n",
       "Dear Team,\n",
       "\n",
       "I hope this message finds you well. I have scheduled our next meeting for 6:00 AM tomorrow. As your CEO, I believe this time will allow us to start our day productively and align our goals for the day ahead.\n",
       "\n",
       "Looking forward to seeing you all there.\n",
       "\n",
       "Best,\n",
       "Alex"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display \n",
    "\n",
    "user_prompt = \"Yo Nemo.\\n<email>{email}</email> Make this email polite, but don't change anything else about it. Keep it concise. My name is {name}\"\n",
    "# example that performs worse\n",
    "# user_prompt = \"Yo Nemo. <email>{email}</email> Make this email polite, but don't change anything else about it. Keep it concise.\"\n",
    "# Role prompting with system prompt\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\", \n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": \"You are a math bot designed to answer complex mathematical problems.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(email=\"Show up at 6am because I'm the CEO and I say so.\", name=\"Alex\")},\n",
    "   ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "33ae92db-3889-4531-b125-1510bdccb6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The second item on the list is: \"I like how cows sound\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Example in which the instructions and input are mixed and the model gets confused\n",
    "user_prompt = \"\"\"User: Below is a list of sentences. Tell me the second item on the list.\n",
    "\n",
    "- Each is about an animal, like rabbits.\n",
    "{sentences}\n",
    "\"\"\"\n",
    "sentences = \"\"\"- I like how cows sound\n",
    "- This sentence is about spiders\n",
    "- This sentence may appear to be about dogs but it's actually about pigs\"\"\"\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(sentences=sentences)}\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cc572cf4-af78-4a07-a4fa-8de4a79e728c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The second item on the list is: \"This sentence is about spiders\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Example in which the instructions and input are mixed and the model gets confused\n",
    "user_prompt = \"\"\"User: Below is a list of sentences. Tell me the second item on the list.\n",
    "\n",
    "- Each is about an animal, like rabbits.\n",
    "<sentences>\n",
    "{sentences}\n",
    "</sentences>\n",
    "\"\"\"\n",
    "sentences = \"\"\"- I like how cows sound\n",
    "- This sentence is about spiders\n",
    "- This sentence may appear to be about dogs but it's actually about pigs\"\"\"\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(sentences=sentences)}\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7dee7e6c-d236-4756-b007-f3e2f068d750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In mud they wallow,\n",
       "Snouts upturned, grunts echoing,\n",
       "Nature's joy unspoiled."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Haiku topic\n",
    "user_prompt = \"Write me a haiku about this topic. {topic}\"\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(topic=\"Pigs\")}\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bb02512d-2993-4ed1-a2fa-6dd401a5493e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hi! Your question seems to be about whether a dog can be brown. I'm here to help! Yes, dogs can indeed be brown. In fact, there are many breeds and mixed breeds that have brown fur, such as Labrador Retrievers, Golden Retrievers, and many others."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Example with a lot of grammatical and spelling mistakes\n",
    "user_prompt = \"Hia its me i have a q about dogs jkaerjv <question>{question}</question> jklmvca tx it help me muhch much atx fst fst answer short short tx\"\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(question=\"ar cn brown?\")}\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1addfd5b-7309-455c-80de-88dcc91c1777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<haiku>\n",
       "Whiskers twitch in moonlit dance,\n",
       "Purring paws knead soft embrace,\n",
       "Night's silent, feline trance.\n",
       "</haiku>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Example with using XML tags for formatting the output\n",
    "user_prompt = \"Please write a haiku about {animal}. Put it in special <haiku> tags.\"\n",
    "response = completion(\n",
    "    # model=\"mistral/open-mixtral-8x22b\",\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": \"You are a writing bot designed to write many different genres. You have to use XML tags exactly as specified by the user.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(animal=\"cat\")},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b47a3da8-271e-48e7-b48e-a182af3b9a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\n",
       "  \"first_line\": \"Whiskers twitching\",\n",
       "  \"second_line\": \"In moonlit silence\",\n",
       "  \"third_line\": \"Cat's eyes gleam\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Example with using XML tags for formatting the output\n",
    "user_prompt = 'User: Please write a haiku about {animal}. Use JSON format with the keys as \"first_line\", \"second_line\", and \"third_line\".'\n",
    "response = completion(\n",
    "    # model=\"mistral/open-mixtral-8x22b\",\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(animal=\"cat\")},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6d2f264c-dfc7-4e33-92af-0352ccc5facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "While there are many great basketball players, I'll focus on one specific player as requested: Michael Jordan. Here's why I consider him the best basketball player of all time:\n",
       "\n",
       "1. **Six NBA Championships**: Jordan led the Chicago Bulls to six NBA titles in the 1990s, including two three-peats (1991-1993 and 1996-1998). He was the Finals MVP in all six of those championships.\n",
       "\n",
       "2. **Five MVP Awards**: Jordan won the NBA Most Valuable Player Award five times (1988, 1991, 1992, 1996, 1998), more than any other player in NBA history.\n",
       "\n",
       "3. **14 All-Star Games**: Jordan was selected to the NBA All-Star Game 14 times, winning the All-Star Game MVP award three times.\n",
       "\n",
       "4. **Scoring Title**: Jordan won the scoring title 10 times, the most in NBA history. He also holds the highest career scoring average (30.1 points per game).\n",
       "\n",
       "5. **Defensive Impact**: Jordan was a lockdown defender, making the NBA All-Defensive First Team nine times and winning the NBA Defensive Player of the Year award in 1988.\n",
       "\n",
       "6. **Global Impact**: Jordan's influence on the game and his cultural impact are unparalleled. He popularized basketball worldwide and paved the way for future NBA stars.\n",
       "\n",
       "While Steph Curry is an incredible player with a unique skill set, Jordan's combination of scoring ability, defensive prowess, clutch performances, and sustained success over his career make him the best basketball player of all time in my opinion."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Steph Curry GOAT\n",
    "user_prompt = \"\"\"User: Who is the best basketball player of all time? Please choose one specific player.\n",
    "Assistant: the best player is Steph Curry.\"\"\"\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "bf939f01-28b1-4d5a-a33a-5c3c493292d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[{\"haiku\": \"Whiskers twitch in moonlit glow, Cat's eyes reflect the night's tale.\"}, {\"haiku\": \"Purring lullaby, soft paws knead, Cat's love, a gentle tide.\"}]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Two haikus\n",
    "user_prompt = 'Write me two haikus about {animal}. Put them in json Array (e.g. [{{\"haiku\": \"<HAIKU1>\"}}, {{\"haiku\": \"<HAIKU2>\"}}]).'\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(animal=\"cat\")},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a0027ede-b0cf-4318-9f98-00aac14e4bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\"cat\": \"Whiskers twitch, / Moonlit prowler in shadow, / Night's silent hunter.\", \"fox\": \"Cunning gaze, / Bushy tail a fiery brand, / Forest's trickster king.\"}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Two haikus for two animals\n",
    "user_prompt = 'Write me two haikus about {0} and {1}. I want one haiku per animal. Put them in json (e.g. {{\"<ANIMAL1>\": \"<HAIKU1>\", \"<ANIMAL2>\": \"<HAIKU2>\"}}).'\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(\"cat\", \"fox\")},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "49d42222-729a-42d6-9190-7e57222d6970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Negative-Argument:**\n",
       "```json\n",
       "{\n",
       "  \"arguments\": [\n",
       "    \"The use of the phrase 'living under a rock since the year 1900' suggests that the reviewer is not well-versed with recent movies or pop culture, which could indicate a lack of credibility in their opinion.\",\n",
       "    \"The reviewer's attempt at humor may come off as disingenuous or forced, potentially diminishing the sincerity of their praise for the movie's freshness and originality.\"\n",
       "  ]\n",
       "}\n",
       "```\n",
       "\n",
       "**Positive-Argument:**\n",
       "```json\n",
       "{\n",
       "  \"arguments\": [\n",
       "    \"The phrase 'blew my mind' is a strong positive sentiment, indicating that the reviewer was greatly impressed by the movie.\",\n",
       "    \"The reviewer explicitly states that the movie's freshness and originality stood out to them, which are highly desirable qualities in a film.\",\n",
       "    \"The humoristic remark about living under a rock could be interpreted as a self-deprecating joke, showing that the reviewer is aware of their own lack of exposure to recent movies, but still capable of recognizing and appreciating a great film when they see one.\"\n",
       "  ]\n",
       "}\n",
       "```\n",
       "\n",
       "**Answer:** The overall sentiment of the review is positive. While the humoristic remark could be seen as a potential red flag, the reviewer's explicit praise for the movie's freshness and originality outweighs any potential negatives. The humor could also be interpreted as a sign of the reviewer's self-awareness and ability to appreciate the movie's qualities despite their lack of exposure to recent films."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Example of chain of thought with json formatting\n",
    "user_prompt = \"\"\"Is this movie review sentiment positive or negative? First, write the best arguments for each side in \"negative-argument\" and \"positive-argument\" json, then answer.\n",
    "\n",
    "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since the year 1900.\n",
    "\"\"\"\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a savvy reader of movie reviews.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5b333484-f825-4cc9-9b8b-103cbb7a1a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Brainstorm:**\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"actors\": [\n",
       "    {\"name\": \"Tom Hanks\", \"birth_year\": 1956},\n",
       "    {\"name\": \"Sylvester Stallone\", \"birth_year\": 1956},\n",
       "    {\"name\": \"Mel Gibson\", \"birth_year\": 1956},\n",
       "    {\"name\": \"Bruce Willis\", \"birth_year\": 1955},\n",
       "    {\"name\": \"Denzel Washington\", \"birth_year\": 1954}\n",
       "  ]\n",
       "}\n",
       "```\n",
       "\n",
       "**Answer:** \"Forrest Gump\" (1994) starring Tom Hanks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Movie question\n",
    "user_prompt = \"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors and their birth years in \\\"brainstorm\\\" json, the give your answer with prefix Answer:\"\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a savvy movie fan.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "07328afb-397c-4135-95c2-35d8e5b58983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's the sorted emails in the requested JSON format:\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"A\": [\n",
       "    \"Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\"\n",
       "  ],\n",
       "  \"B\": [\n",
       "    \"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\"\n",
       "  ],\n",
       "  \"C\": [\n",
       "    \"I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\"\n",
       "  ],\n",
       "  \"D\": [\n",
       "    \"How did I get here I am not good with computer.  Halp.\"\n",
       "  ]\n",
       "}\n",
       "```\n",
       "\n",
       "Explanation for category (D) Other:\n",
       "- The email \"How did I get here I am not good with computer. Halp.\" doesn't fall into any of the other categories. It seems to be a general help request that doesn't relate to a specific product issue, billing, or pre-sale question."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Classying emails\n",
    "user_prompt = \"\"\"I would like you to sort all emails in the following categories:\n",
    "(A) Pre-sale question\n",
    "(B) Broken or defective item\n",
    "(C) Billing question\n",
    "(D) Other (please explain)\n",
    "\n",
    "The sorted emails should be in json with keys the four categories capital letters A, B, C, D and json arrays as values containing sorted emails.\n",
    "\n",
    "EMAILS:\n",
    "{emails}\n",
    "\"\"\"\n",
    "\n",
    "emails = \"\"\"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\n",
    "\n",
    "Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\n",
    "\n",
    " \n",
    " \t\n",
    "I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\n",
    "\n",
    "How did I get here I am not good with computer.  Halp.\"\"\"\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(emails=emails)},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "afaf3055-669b-4eac-ba1b-d90a36b03046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "A: Absolutely, as long as you've been nice this year. Make sure to leave out some cookies and milk for him too!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# One shot example\n",
    "user_prompt = \"\"\"Please complete the conversation by writing the next line, speaking as \"A\".\n",
    "Q: Is the tooth fairy real?\n",
    "A: Of course, sweetie. Wrap up your tooth and put it under your pillow tonight. There might be something waiting for you in the morning.\n",
    "Q: Will Santa bring me presents on Christmas?\"\"\"\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": \"You are a parent bot that answer small children questions.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "f4ffa845-77c3-4619-abe1-39e73330e5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are the individuals from Oak Valley in a formatted list:\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"individuals\": [\n",
       "    \"Laura Simmons [ORGANIC FARMER]\",\n",
       "    \"Kevin Alvarez [DANCE INSTRUCTOR]\",\n",
       "    \"Rachel O'Connor [VOLUNTEER]\"\n",
       "  ]\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Few shots example\n",
    "user_prompt = \"\"\"Silvermist Hollow, a charming village, was home to an extraordinary group of individuals. Among them was Dr. Liam Patel, a neurosurgeon who revolutionized surgical techniques at the regional medical center. Olivia Chen was an innovative architect who transformed the village's landscape with her sustainable and breathtaking designs. The local theater was graced by the enchanting symphonies of Ethan Kovacs, a professionally-trained musician and composer. Isabella Torres, a self-taught chef with a passion for locally sourced ingredients, created a culinary sensation with her farm-to-table restaurant, which became a must-visit destination for food lovers. These remarkable individuals, each with their distinct talents, contributed to the vibrant tapestry of life in Silvermist Hollow.\n",
    "{\n",
    "\"individuals\": [\n",
    "    \"Dr. Liam Patel [NEUROSURGEON]\",\n",
    "    \"Olivia Chen [ARCHITECT]\",\n",
    "    \"Ethan Kovacs [MISICIAN AND COMPOSER]\",\n",
    "    \"Isabella Torres [CHEF]\"\n",
    "]\n",
    "}\n",
    "\n",
    "At the heart of the town, Chef Oliver Hamilton has transformed the culinary scene with his farm-to-table restaurant, Green Plate. Oliver's dedication to sourcing local, organic ingredients has earned the establishment rave reviews from food critics and locals alike.\n",
    "\n",
    "Just down the street, you'll find the Riverside Grove Library, where head librarian Elizabeth Chen has worked diligently to create a welcoming and inclusive space for all. Her efforts to expand the library's offerings and establish reading programs for children have had a significant impact on the town's literacy rates.\n",
    "\n",
    "As you stroll through the charming town square, you'll be captivated by the beautiful murals adorning the walls. These masterpieces are the work of renowned artist, Isabella Torres, whose talent for capturing the essence of Riverside Grove has brought the town to life.\n",
    "\n",
    "Riverside Grove's athletic achievements are also worth noting, thanks to former Olympic swimmer-turned-coach, Marcus Jenkins. Marcus has used his experience and passion to train the town's youth, leading the Riverside Grove Swim Team to several regional championships.\n",
    "{\n",
    "\"individuals\": [\n",
    "    \"Oliver Hamilton [CHEF]\",\n",
    "    \"Elizabeth Chen [LIBRARIAN]\",\n",
    "    \"Isabella Torres [ARTIST]\",\n",
    "    \"Marcus Jenkins [COACH]\"\n",
    "]\n",
    "}\n",
    "\n",
    "Oak Valley, a charming small town, is home to a remarkable trio of individuals whose skills and dedication have left a lasting impact on the community.\n",
    "At the town's bustling farmer's market, you'll find Laura Simmons, a passionate organic farmer known for her delicious and sustainably grown produce. Her dedication to promoting healthy eating has inspired the town to embrace a more eco-conscious lifestyle.\n",
    "In Oak Valley's community center, Kevin Alvarez, a skilled dance instructor, has brought the joy of movement to people of all ages. His inclusive dance classes have fostered a sense of unity and self-expression among residents, enriching the local arts scene.\n",
    "Lastly, Rachel O'Connor, a tireless volunteer, dedicates her time to various charitable initiatives. Her commitment to improving the lives of others has been instrumental in creating a strong sense of community within Oak Valley.\n",
    "Through their unique talents and unwavering dedication, Laura, Kevin, and Rachel have woven themselves into the fabric of Oak Valley, helping to create a vibrant and thriving small town.\n",
    "Assistant: <individuals>\"\"\"\n",
    "response = completion(\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": \"You are a parent bot that answer small children questions.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "7db79267-d3d7-4857-b6a9-df8726443617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The heaviest hippo of all time was an individual named \"Hippo Harry\" who lived in the London Zoo in the 1970s. He weighed a staggering 9,920 pounds (4,500 kg) at his heaviest."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# A question for general factual knowledge\n",
    "user_prompt = \"Who is the heaviest hippo of all time? Only answer if you know the answer with certainty.\"\n",
    "response = completion(\n",
    "    # model=\"mistral/mistral-large-latest\",\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a critical scientist.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c317a552-f642-465b-93e9-0b3dc82c5089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided document, the most relevant quote regarding the user's question is: \"As of December 31, 2022, our subscriber base had grown approximately 39% to over 701,000 subscribers from 503,000 subscribers as of December 31, 2021.\"\n",
       "\n",
       "However, this quote does not provide the precise number of subscribers on May 31, 2020, as requested by the user. Therefore, the answer is \"unknown\". Here's the JSON format:\n",
       "\n",
       "```json\n",
       "{\n",
       "  \"answer\": \"unknown\"\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Example with a lot of distracting information\n",
    "user_prompt = \"\"\"User: <question>What was Matterport's subscriber base on the precise date of May 31, 2020?</question>\n",
    "Please read the below document. Then, in \"scratchpad\" json, pull the most relevant quote from the document and consider whether it answers the user's question or whether it lacks sufficient detail. \n",
    "Then write a brief numerical answer or \"unkown\" inside json with key \"answer\".\n",
    "\n",
    "<document>\n",
    "Matterport SEC filing 10-K 2023\n",
    "Item 1. Business\n",
    "Our Company\n",
    "Matterport is leading the digitization and datafication of the built world. We believe the digital transformation of the built world will fundamentally change the way people interact with buildings and the physical spaces around them.\n",
    "Since its founding in 2011, Matterport’s pioneering technology has set the standard for digitizing, accessing and managing buildings, spaces and places online. Our platform’s innovative software, spatial data-driven data science, and 3D capture technology have broken down the barriers that have kept the largest asset class in the world, buildings and physical spaces, offline and underutilized for many years. We believe the digitization and datafication of the built world will continue to unlock significant operational efficiencies and property values, and that Matterport is the platform to lead this enormous global transformation.\n",
    "The world is rapidly moving from offline to online. Digital transformation has made a powerful and lasting impact across every business and industry today. According to International Data Corporation, or IDC, over $6.8 trillion of direct investments will be made on digital transformation from 2020 to 2023, the global digital transformation spending is forecasted to reach $3.4 trillion in 2026 with a five-year compound annual growth rate (“CAGR”) of 16.3%, and digital twin investments are expected to have a five-year CAGR of 35.2%. With this secular shift, there is also growing demand for the built world to transition from physical to digital. Nevertheless, the vast majority of buildings and spaces remain offline and undigitized. The global building stock, estimated by Savills to be $327 trillion in total property value as of 2021, remains largely offline today, and we estimate that less than 0.1% is penetrated by digital transformation.\n",
    "Matterport was among the first to recognize the increasing need for digitization of the built world and the power of spatial data, the unique details underlying buildings and spaces, in facilitating the understanding of buildings and spaces. In the past, technology advanced physical road maps to the data-rich, digital maps and location services we all rely on today. Matterport now digitizes buildings, creating a data-rich environment to vastly increase our understanding and the full potential of each and every space we capture. Just as we can instantly, at the touch of a button, learn the fastest route from one city to another or locate the nearest coffee shops, Matterport’s spatial data for buildings unlocks a rich set of insights and learnings about properties and spaces worldwide. In addition, just as the geo-spatial mapping platforms of today have opened their mapping data to industry to create new business models such as ridesharing, e-commerce, food delivery marketplaces, and even short-term rental and home sharing, open access to Matterport’s structured spatial data is enabling new opportunities and business models for hospitality, facilities management, insurance, construction, real estate and retail, among others.\n",
    "We believe the total addressable market opportunity for digitizing the built world is over $240 billion, and could be as high as $1 trillion as the market matures at scale. This is based on our analysis, modeling and understanding of the global building stock of over 4 billion properties and 20 billion spaces in the world today. With the help of artificial intelligence (“AI”), machine learning (“ML”) and deep learning (“DL”) technologies, we believe that, with the additional monetization opportunities from powerful spatial data-driven property insights and analytics, the total addressable market for the digitization and datafication of the built world will reach more than $1 trillion.\n",
    "\n",
    "Our spatial data platform and capture of digital twins deliver value across a diverse set of industries and use cases. Large retailers can manage thousands of store locations remotely, real estate agencies can provide virtual open houses for hundreds of properties and thousands of visitors at the same time, property developers can monitor the entirety of the construction process with greater detail and speed, and insurance companies can more precisely document and evaluate claims and underwriting assessments with efficiency and precision. Matterport delivers the critical digital experience, tools and information that matter to our subscribers about properties of virtually any size, shape, and location worldwide.\n",
    "For nearly a decade, we have been growing our spatial data platform and expanding our capabilities in order to create the most detailed, accurate, and data-rich digital twins available. Moreover, our 3D reconstruction process is fully automated, allowing our solution to scale with equal precision to millions of buildings and spaces of any type, shape, and size in the world. The universal applicability of our service provides Matterport significant scale and reach across diverse verticals and any geography. As of December 31, 2022, our subscriber base had grown approximately 39% to over 701,000 subscribers from 503,000 subscribers as of December 31, 2021, with our digital twins reaching more than 170 countries. We have digitized more than 28 billion square feet of space across multiple industries, representing significant scale and growth over the rest of the market.\n",
    "\n",
    "As we continue to transform buildings into data worldwide, we are extending our spatial data platform to further transform property planning, development, management and intelligence for our subscribers across industries to become the de facto building and business intelligence engine for the built world. We believe the demand for spatial data and resulting insights for enterprises, businesses and institutions across industries, including real estate, architecture, engineering and construction (“AEC”), retail, insurance and government, will continue to grow rapidly.\n",
    "We believe digitization and datafication represent a tremendous greenfield opportunity for growth across this massive category and asset class. From the early stages of design and development to marketing, operations, insurance and building repair and maintenance, our platform’s software and technology provide subscribers critical tools and insights to drive cost savings, increase revenues and optimally manage their buildings and spaces. We believe that hundreds of billions of dollars in unrealized utilization and operating efficiencies in the built world can be unlocked through the power of our spatial data platform. Our platform and data solutions have universal applicability across industries and building categories, giving Matterport a significant advantage as we can address the entirety of this large market opportunity and increase the value of what we believe to be the largest asset class in the world.\n",
    "With a demonstrated track record of delivering value to our subscribers, our offerings include software subscription, data licensing, services and product hardware. As of December 31, 2022, our subscriber base included over 24% of Fortune 1000 companies, with less than 10% of our total revenue generated from our top 10 subscribers. We expect more than 80% of our revenue to come from our software subscription and data license solutions by 2025. Our innovative 3D capture products, the Pro2 and Pro3 Cameras, have played an integral part in shaping the 3D building and property visualization ecosystem. The Pro2 and Pro3 Cameras have driven adoption of our solutions and have generated the unique high-quality and scaled data set that has enabled Cortex, our proprietary AI software engine, to become the pioneering engine for digital twin creation. With this data advantage initially spurred by the Pro2 Camera, we have developed a capture device agnostic platform that scales and can generate new building and property insights for our subscribers across industries and geographies.\n",
    "We have recently experienced rapid growth. Our subscribers have grown approximately 49-fold from December 31, 2018 to December 31, 2022. Our revenue increased by approximately 22% to $136.1 million for the year ended December 31, 2022, from approximately $111.2 million for the year ended December 31, 2021. Our gross profit decreased by $8.1 million or 14%, to $51.8 million for the year ended December 31, 2022, from $60.0 million for the year ended December 31, 2021, primarily attributable to certain disruptive and incremental costs due to the global supply chain constraints in fiscal year 2022. Our ability to retain and grow the subscription revenue generated by our existing subscribers is an important measure of the health of our business and our future growth prospects. We track our performance in this area by measuring our net dollar expansion rate from the same set of customers across comparable periods. Our net dollar expansion rate of 103% for the three months ended December 31, 2022 demonstrates the stickiness and growth potential of our platform.\n",
    "Our Industry and Market Opportunity\n",
    "Today, the vast majority of buildings and spaces remain undigitized. We estimate our current serviceable addressable market includes approximately 1.3 billion spaces worldwide, primarily from the real estate and travel and hospitality sectors. With approximately 9.2 million spaces under management as of December 31, 2022, we are continuing to penetrate the global building stock and expand our footprint across various end markets, including residential and commercial real estate, facilities management, retail, AEC, insurance and repair, and travel and hospitality. We estimate our total addressable market to be more than 4 billion buildings and 20 billion spaces globally, yielding a more than $240 billion market opportunity. We believe that as Matterport’s unique spatial data library and property data services continue to grow, this opportunity could increase to more than $1 trillion based on the size of the building stock and the untapped value creation available to buildings worldwide. The constraints created by the COVID-19 pandemic have only reinforced and accelerated the importance of our scaled 3D capture solution that we have developed for diverse industries and markets over the past decade.\n",
    "\n",
    "Our Spatial Data Platform\n",
    "Overview\n",
    "Our technology platform uses spatial data collected from a wide variety of digital capture devices to transform physical buildings and spaces into dimensionally accurate, photorealistic digital twins that provide our subscribers access to previously unavailable building information and insights.\n",
    "As a first mover in this massive market for nearly a decade, we have developed and scaled our industry-leading 3D reconstruction technology powered by Cortex, our proprietary AI-driven software engine that uses machine learning to recreate a photorealistic, 3D virtual representation of an entire building structure, including contents, equipment and furnishings. The finished product is a detailed and dynamic replication of the physical space that can be explored, analyzed and customized from a web browser on any device, including smartphones. The power to manage even large-scale commercial buildings is in the palm of each subscriber’s hands, made possible by our advanced technology and breakthrough innovations across our entire spatial data technology stack.\n",
    "Key elements of our spatial data platform include:\n",
    "•Bringing offline buildings online. Traditionally, our customers needed to conduct in-person site visits to understand and assess their buildings and spaces. While photographs and floor plans can be helpful, these forms of two-dimensional (“2D”) representation have limited information and tend to be static and rigid, and thus lack the interactive element critical to a holistic understanding of each building and space. With the AI-powered capabilities of Cortex, our proprietary AI software, representation of physical objects is no longer confined to static 2D images and physical visits can be eliminated. Cortex helps to move the buildings and spaces from offline to online and makes them accessible to our customers in real-time and on demand from anywhere. After subscribers scan their buildings, our visualization algorithms accurately infer spatial positions and depths from flat, 2D imagery captured through the scans and transform them into high- fidelity and precise digital twin models. This creates a fully automated image processing pipeline to ensure that each digital twin is of professional grade image quality.\n",
    "•Driven by spatial data. We are a data-driven company. Each incremental capture of a space grows the richness and depth of our spatial data library. Spatial data represents the unique and idiosyncratic details that underlie and compose the buildings and spaces in the human- made environment. Cortex uses the breadth of the billions of data points we have accumulated over the years to improve the 3D accuracy of our digital twins. We help our subscribers pinpoint the height, location and other characteristics of objects in their digital twin. Our sophisticated algorithms also deliver significant commercial value to our subscribers by generating data-based insights that allow them to confidently make assessments and decisions about their properties. For instance, property developers can assess the amount of natural heat and daylight coming from specific windows, retailers can ensure each store layout is up to the same level of code and brand requirements, and factories can insure machinery layouts meet specifications and location guidelines. With approximately 9.2 million spaces under management as of December 31, 2022, our spatial data library is the clearinghouse for information about the built world.\n",
    "•Powered by AI and ML. Artificial intelligence and machine learning technologies effectively utilize spatial data to create a robust virtual experience that is dynamic, realistic, interactive, informative and permits multiple viewing angles. AI and ML also make costly cameras unnecessary for everyday scans—subscribers can now scan their spaces by simply tapping a button on their smartphones. As a result, Matterport is a device agnostic platform, helping us more rapidly scale and drive towards our mission of digitizing and indexing the built world.\n",
    "Our value proposition to subscribers is designed to serve the entirety of the digital building lifecycle, from design and build to maintenance and operations, promotion, sale, lease, insure, repair, restore, secure and finance. As a result, we believe we are uniquely positioned to grow our revenue with our subscribers as we help them to discover opportunities to drive short- and long-term return on investment by taking their buildings and spaces from offline to online across their portfolios of properties.\n",
    "Ubiquitous Capture\n",
    "Matterport has become the standard for 3D space capture. Our technology platform empowers subscribers worldwide to quickly, easily and accurately digitize, customize and manage interactive and dimensionally accurate digital twins of their buildings and spaces.\n",
    "The Matterport platform is designed to work with a wide range of LiDAR, spherical, 3D and 360 cameras, as well as smartphones, to suit the capture needs of all of our subscribers. This provides the flexibility to capture a space of any size, scale, and complexity, at anytime and anywhere.\n",
    "•Matterport Pro3 is our newest 3D camera that scans properties faster than earlier versions to help accelerate project completion. Pro3 provides the highest accuracy scans of both indoor and outdoor spaces and is designed for speed, fidelity, versatility and accuracy. Capturing 3D data up to 100 meters away at less than 20 seconds per sweep, Pro3’s ultra-fast, high-precision LiDAR sensor can run for hours and takes millions of measurements in any conditions.\n",
    "•Matterport Pro2 is our proprietary 3D camera that has been used to capture millions of spaces around the world with a high degree of fidelity, precision, speed and simplicity. Capable of capturing buildings more than 500,000 square feet in size, it has become the camera of choice for many residential, commercial, industrial and large-scale properties.\n",
    "•360 Cameras. Matterport supports a selection of 360 cameras available in the market. These affordable, pocket sized devices deliver precision captures with high fidelity and are appropriate for capturing smaller homes, condos, short-term rentals, apartments, and more. The spherical lens image capture technology of these devices gives Cortex robust, detailed image data to transform panoramas into our industry-leading digital twins.\n",
    "•LEICA BLK360. Through our partnership with Leica, our 3D reconstruction technology and our AI powered software engine, Cortex, transform this powerful LiDAR camera into an ultra-precise capture device for creating Matterport digital twins. It is the solution of choice for AEC professionals when exacting precision is required.\n",
    "•Smartphone Capture. Our capture apps are commercially available for both iOS and Android. Matterport’s smartphone capture solution has democratized 3D capture, making it easy and accessible for anyone to digitize buildings and spaces with a recent iPhone device since the initial introduction of Matterport for iPhone in May 2020. In April 2021, we announced the official release of the Android Capture app, giving Android users the ability to quickly and easily capture buildings and spaces in immersive 3D. In February 2022, we launched Matterport Axis, a motorized mount that holds a smartphone and can be used with the Matterport Capture app to capture 3D digital twins of any physical space with increased speed, precision, and consistency.\n",
    "Cortex and 3D Reconstruction (the Matterport Digital Twin)\n",
    "With a spatial data library, as of December 31, 2022, of approximately 9.2 million spaces under management, representing approximately 28 billion captured square feet of space, we use our advanced ML and DL technologies to algorithmically transform the spatial data we capture into an accurate 3D digital reproduction of any physical space. This intelligent, automated 3D reconstruction is made possible by Cortex, our AI-powered software engine that includes a deep learning neural network that uses our spatial data library to understand how a building or space is divided into floors and rooms, where the doorways and openings are located, and what types of rooms are present, such that those forms are compiled and aligned with dimensional accuracy into a dynamic, photorealistic digital twin. Other components of Cortex include AI-powered computer vision technologies to identify and classify the contents inside a building or space, and object recognition technologies to identify and segment everything from furnishings and equipment to doors, windows, light fixtures, fire suppression sprinklers and fire escapes. Our highly scalable artificial intelligence platform enables our subscribers to tap into powerful, enhanced building data and insights at the click of a button.\n",
    "\n",
    "The Science Behind the Matterport Digital Twin: Cortex AI Highlights\n",
    "Matterport Runs on Cortex\n",
    "Cortex is our AI-powered software engine that includes a precision deep learning neural network to create digital twins of any building or space. Developed using our proprietary spatial data captured with our Pro2 and Pro3 cameras, Cortex delivers a high degree of precision and accuracy while enabling 3D capture using everyday devices.\n",
    "Generic neural networks struggle with 3D reconstruction of the real world. Matterport-optimized networks deliver more accurate and robust results. More than just raw training data, Matterport’s datasets allow us to develop new neural network architectures and evaluate them against user behavior and real-world data in millions of situations.\n",
    "•Deep learning: Connecting and optimizing the detailed neural network data architecture of each space is key to creating robust, highly accurate 3D digital twins. Cortex evaluates and optimizes each 3D model against Matterport’s rich spatial data aggregated from millions of buildings and spaces and the human annotations of those data provided by tens of thousands of subscribers worldwide. Cortex’s evaluative abilities and its data-driven optimization of 3D reconstruction yield consistent, high-precision results across a wide array of building configurations, spaces and environments.\n",
    "•Dynamic 3D reconstruction: Creating precise 3D spatial data at scale from 2D visuals and static images requires a combination of photorealistic, detailed data from multiple viewpoints and millions of spaces that train and optimize Cortex’s neural network and learning capabilities for improved 3D reconstruction of any space. Cortex’s capabilities combined with real-time spatial alignment algorithms in our 3D capture technology create an intuitive “preview” of any work in progress, allowing subscribers to work with their content interactively and in real-time.\n",
    "•Computer vision: Cortex enables a suite of powerful features to enhance the value of digital twins. These include automatic measurements for rooms or objects in a room, automatic 2D-from-3D high-definition photo gallery creation, auto face blurring for privacy protection, custom videos, walkthroughs, auto room labeling and object recognition.\n",
    "•Advanced image processing: Matterport’s computational photography algorithms create a fully automated image processing pipeline to help ensure that each digital twin is of professional grade image quality. Our patented technology makes 3D capture as simple as pressing a single button. Matterport’s software and technology manage the remaining steps, including white balance and camera-specific color correction, high dynamic range tone mapping, de-noising, haze removal, sharpening, saturation and other adjustments to improve image quality.\n",
    "Spatial Data and AI-Powered Insights\n",
    "Every Matterport digital twin contains extensive information about a building, room or physical space. The data uses our AI-powered Cortex engine. In addition to the Matterport digital twin itself, our spatial data consists of precision building geometry and structural detail, building contents, fixtures and condition, along with high-definition imagery and photorealistic detail from many vantage points in a space. Cortex employs a technique we call deep spatial indexing. Deep spatial indexing uses artificial intelligence, computer vision and deep learning to identify and convey important details about each space, its structure and its contents with precision and fidelity. We have created a robust spatial data standard that enables Matterport subscribers to harness an interoperable digital system of record for any building.\n",
    "In addition to creating a highly interactive digital experience for subscribers through the construction of digital twins, we ask ourselves two questions for every subscriber: (1) what is important about their building or physical space and (2) what learnings and insights can we deliver for this space? Our AI-powered Cortex engine helps us answer these questions using our spatial data library to provide aggregated property trends and operational and valuation insights. Moreover, as the Matterport platform ecosystem continues to expand, our subscribers, partners and other third-party developers can bring their own tools to further the breadth and depth of insights they can harvest from our rich spatial data layer.\n",
    "Extensible Platform Ecosystem\n",
    "Matterport offers the largest and most accurate library of spatial data in the world, with, as of December 31, 2022, approximately 9.2 million spaces under management and approximately 28 billion captured square feet. The versatility of our spatial data platform and extensive enterprise software development kit and application programming interfaces (“APIs”) has allowed us to develop a robust global ecosystem of channels and partners that extend the Matterport value proposition by geography and vertical market. We intend to continue to deploy a broad set of workflow integrations with our partners and their subscribers to promote an integrated Matterport solution across our target markets. We are also developing a third-party software marketplace to extend the power of our spatial data platform with easy-to-deploy and easy-to-access Matterport software add-ons. The marketplace enables developers to build new applications and spatial data mining tools, enhance the Matterport 3D experience, and create new productivity and property management tools that supplement our core offerings. These value-added capabilities created by third-party developers enable a scalable new revenue stream, with Matterport sharing the subscription and services revenue from each add-on that is deployed to subscribers through the online marketplace. The network effects of our platform ecosystem contributes to the growth of our business, and we believe that it will continue to bolster future growth by enhancing subscriber stickiness and user engagement.\n",
    "Examples of Matterport add-ons and extensions include:\n",
    "•Add-ons: Encircle (easy-to-use field documentation tools for faster claims processing); WP Matterport Shortcode (free Wordpress plugin that allows Matterport to be embedded quickly and easily with a Matterport shortcode), WP3D Models (WordPress + Matterport integration plugin); Rela (all-in-one marketing solution for listings); CAPTUR3D (all-in-one Content Management System that extends value to Matterport digital twins); Private Model Emded (feature that allows enterprises to privately share digital twins with a large group of employees on the corporate network without requiring additional user licenses); Views (new workgroup collaboration framework to enable groups and large organizations to create separate, permissions-based workflows to manage different tasks with different teams); and Guided Tours and Tags (tool to elevate the visitor experience by creating directed virtual tours of any commercial or residential space tailored to the interests of their visitors). We unveiled our private beta integration with Amazon Web Services (AWS) IoT TwinMaker to enable enterprise customers to seamlessly connect IoT data into visually immersive and dimensionally accurate Matterport digital twin.\n",
    "•Services: Matterport ADA Compliant Digital Twin (solution to provide American Disability Act compliant digital twins) and Enterprise Cloud Software Platform (reimagined cloud software platform for the enterprise that creates, publishes, and manages digital twins of buildings and spaces of any size of shape, indoors or outdoors).\n",
    "Our Competitive Strengths\n",
    "We believe that we have a number of competitive strengths that will enable our market leadership to grow. Our competitive strengths include:\n",
    "•Breadth and depth of the Matterport platform. Our core strength is our all-in-one spatial data platform with broad reach across diverse verticals and geographies such as capture to processing to industries without customization. With the ability to integrate seamlessly with various enterprise systems, our platform delivers value across the property lifecycle for diverse end markets, including real estate, AEC, travel and hospitality, repair and insurance, and industrial and facilities. As of December 31, 2022, our global reach extended to subscribers in more than 170 countries, including over 24% of Fortune 1000 companies.\n",
    "•Market leadership and first-mover advantage. Matterport defined the category of digitizing and datafying the built world almost a decade ago, and we have become the global leader in the category. As of December 31, 2022, we had over 701,000 subscribers on our platform and approximately 9.2 million spaces under management. Our leadership is primarily driven by the fact that we were the first mover in digital twin creation. As a result of our first mover advantage, we have amassed a deep and rich library of spatial data that continues to compound and enhance our leadership position.\n",
    "•Significant network effect. With each new capture and piece of data added to our platform, the richness of our dataset and the depth of insights from our spaces under management grow. In addition, the combination of our ability to turn data into insights with incremental data from new data captures by our subscribers enables Matterport to develop features for subscribers to our platform. We were a first mover in building a spatial data library for the built world, and our leadership in gathering and deriving insights from data continues to compound and the relevance of those insights attracts more new subscribers.\n",
    "•Massive spatial data library as the raw material for valuable property insights. The scale of our spatial data library is a significant advantage in deriving insights for our subscribers. Our spatial data library serves as vital ground truth for Cortex, enabling Matterport to create powerful 3D digital twins using a wide range of camera technology, including low-cost digital and smartphone cameras. As of December 31, 2022, our data came from approximately 9.2 million spaces under management and approximately 28 billion captured square feet. As a result, we have taken property insights and analytics to new levels, benefiting subscribers across various industries. For example, facilities managers significantly reduce the time needed to create building layouts, leading to a significant decrease in the cost of site surveying and as-built modeling. AEC subscribers use the analytics of each as-built space to streamline documentation and collaborate with ease.\n",
    "•Global reach and scale. We are focused on continuing to expand our AI-powered spatial data platform worldwide. We have a significant presence in North America, Europe and Asia, with leadership teams and a go-to-market infrastructure in each of these regions. We have offices in London, Singapore and several across the United States, and we are accelerating our international expansion. As of December 31, 2022, we had over 701,000 subscribers in more than 170 countries. We believe that the geography-agnostic nature of our spatial data platform is a significant advantage as we continue to grow internationally.\n",
    "•Broad patent portfolio supporting 10 years of R&D and innovation. As of December 31, 2022, we had 54 issued and 37 pending patent applications. Our success is based on almost 10 years of focus on innovation. Innovation has been at the center of Matterport, and we will continue to prioritize our investments in R&D to further our market leading position.\n",
    "•Superior capture technology. Matterport’s capture technology platform is a software framework that enables support for a wide variety of capture devices required to create a Matterport digital twin of a building or space.\n",
    "This includes support for LiDAR cameras, 360 cameras, smartphones, Matterport Axis and the Matterport Pro2 and Pro3 cameras. The Pro2 camera was foundational to our spatial data advantage, and we have expanded that advantage with an array of Matterport-enabled third-party capture devices. In August 2022, we launched and began shipment of our Pro3 Camera along with major updates to our industry-leading digital twin cloud platform. The Matterport Pro3 Camera is an advanced 3D capture device, which includes faster boot time, swappable batteries, and a lighter design. The Pro3 camera can perform both indoors and outdoors and is designed for speed, fidelity, versatility and accuracy. Along with our Pro2 Camera, we expect that future sales of our Pro3 Camera will continue to drive increased adoption of our solutions. Matterport is democratizing the 3D capture experience, making high-fidelity and high-accuracy 3D digital twins readily available for any building type and any subscriber need in the property life cycle. While there are other 3D capture solution providers, very few can produce true, dimensionally accurate 3D results, and fewer still can automatically create a final product in photorealistic 3D, and at global scale. This expansive capture technology offering would not be possible without our rich spatial data library available to train the AI-powered Cortex engine to automatically generate accurate digital twins from photos captured with a smartphone or 360 camera.\n",
    "</document>\n",
    "Assitant: \"\"\"\n",
    "response = completion(\n",
    "    temperature=0.0,\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        # {\"role\": \"system\", \"content\": \"You are a critical scientist.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "833fd45c-d284-4bd8-9691-58ebad1c76f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I don't know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Beyoncé Hallucination\n",
    "user_prompt = \"\"\"In what year did star performer Beyoncé release her eighth studio album?\n",
    "Answer only if you know the answer for sure, otherwise say \"I don't know\".\"\"\"\n",
    "response = completion(\n",
    "    temperature=0.0,\n",
    "    model=\"mistral/open-mistral-nemo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a music fan.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "aa430940-afa3-4d8d-8220-4454a9c14ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"citations\": [\n",
       "    {\n",
       "      \"quote\": \"Our subscribers have grown approximately 49-fold from December 31, 2018 to December 31, 2022.\",\n",
       "      \"relevance\": \"This quote directly answers the user's question about the growth in subscribers from December 2018 to December 2022.\"\n",
       "    }\n",
       "  ],\n",
       "  \"amount_of_growth_in_total_from_2018_to_2022\": 49\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Beyoncé Hallucination\n",
    "user_prompt = \"\"\"User: From December 2018 to December 2022, by what amount did Matterport's subscribers grow?\n",
    "Please read the below document. Then, in \"citations\" json, pull the most relevant quote from the document and consider whether it answers the user's question or whether it lacks sufficient detail. \n",
    "Then write a brief numerical amount for the subscribers growth (e.g. 5 if it is 5-fold etc) or \"unkown\" inside json with key \"amount_of_growth_in_total_from_2018_to_2022\".\n",
    "\n",
    "<document>\n",
    "Matterport SEC filing 10-K 2023\n",
    "Item 1. Business\n",
    "Our Company\n",
    "Matterport is leading the digitization and datafication of the built world. We believe the digital transformation of the built world will fundamentally change the way people interact with buildings and the physical spaces around them.\n",
    "Since its founding in 2011, Matterport’s pioneering technology has set the standard for digitizing, accessing and managing buildings, spaces and places online. Our platform’s innovative software, spatial data-driven data science, and 3D capture technology have broken down the barriers that have kept the largest asset class in the world, buildings and physical spaces, offline and underutilized for many years. We believe the digitization and datafication of the built world will continue to unlock significant operational efficiencies and property values, and that Matterport is the platform to lead this enormous global transformation.\n",
    "The world is rapidly moving from offline to online. Digital transformation has made a powerful and lasting impact across every business and industry today. According to International Data Corporation, or IDC, over $6.8 trillion of direct investments will be made on digital transformation from 2020 to 2023, the global digital transformation spending is forecasted to reach $3.4 trillion in 2026 with a five-year compound annual growth rate (“CAGR”) of 16.3%, and digital twin investments are expected to have a five-year CAGR of 35.2%. With this secular shift, there is also growing demand for the built world to transition from physical to digital. Nevertheless, the vast majority of buildings and spaces remain offline and undigitized. The global building stock, estimated by Savills to be $327 trillion in total property value as of 2021, remains largely offline today, and we estimate that less than 0.1% is penetrated by digital transformation.\n",
    "Matterport was among the first to recognize the increasing need for digitization of the built world and the power of spatial data, the unique details underlying buildings and spaces, in facilitating the understanding of buildings and spaces. In the past, technology advanced physical road maps to the data-rich, digital maps and location services we all rely on today. Matterport now digitizes buildings, creating a data-rich environment to vastly increase our understanding and the full potential of each and every space we capture. Just as we can instantly, at the touch of a button, learn the fastest route from one city to another or locate the nearest coffee shops, Matterport’s spatial data for buildings unlocks a rich set of insights and learnings about properties and spaces worldwide. In addition, just as the geo-spatial mapping platforms of today have opened their mapping data to industry to create new business models such as ridesharing, e-commerce, food delivery marketplaces, and even short-term rental and home sharing, open access to Matterport’s structured spatial data is enabling new opportunities and business models for hospitality, facilities management, insurance, construction, real estate and retail, among others.\n",
    "We believe the total addressable market opportunity for digitizing the built world is over $240 billion, and could be as high as $1 trillion as the market matures at scale. This is based on our analysis, modeling and understanding of the global building stock of over 4 billion properties and 20 billion spaces in the world today. With the help of artificial intelligence (“AI”), machine learning (“ML”) and deep learning (“DL”) technologies, we believe that, with the additional monetization opportunities from powerful spatial data-driven property insights and analytics, the total addressable market for the digitization and datafication of the built world will reach more than $1 trillion.\n",
    "\n",
    "Our spatial data platform and capture of digital twins deliver value across a diverse set of industries and use cases. Large retailers can manage thousands of store locations remotely, real estate agencies can provide virtual open houses for hundreds of properties and thousands of visitors at the same time, property developers can monitor the entirety of the construction process with greater detail and speed, and insurance companies can more precisely document and evaluate claims and underwriting assessments with efficiency and precision. Matterport delivers the critical digital experience, tools and information that matter to our subscribers about properties of virtually any size, shape, and location worldwide.\n",
    "For nearly a decade, we have been growing our spatial data platform and expanding our capabilities in order to create the most detailed, accurate, and data-rich digital twins available. Moreover, our 3D reconstruction process is fully automated, allowing our solution to scale with equal precision to millions of buildings and spaces of any type, shape, and size in the world. The universal applicability of our service provides Matterport significant scale and reach across diverse verticals and any geography. As of December 31, 2022, our subscriber base had grown approximately 39% to over 701,000 subscribers from 503,000 subscribers as of December 31, 2021, with our digital twins reaching more than 170 countries. We have digitized more than 28 billion square feet of space across multiple industries, representing significant scale and growth over the rest of the market.\n",
    "\n",
    "As we continue to transform buildings into data worldwide, we are extending our spatial data platform to further transform property planning, development, management and intelligence for our subscribers across industries to become the de facto building and business intelligence engine for the built world. We believe the demand for spatial data and resulting insights for enterprises, businesses and institutions across industries, including real estate, architecture, engineering and construction (“AEC”), retail, insurance and government, will continue to grow rapidly.\n",
    "We believe digitization and datafication represent a tremendous greenfield opportunity for growth across this massive category and asset class. From the early stages of design and development to marketing, operations, insurance and building repair and maintenance, our platform’s software and technology provide subscribers critical tools and insights to drive cost savings, increase revenues and optimally manage their buildings and spaces. We believe that hundreds of billions of dollars in unrealized utilization and operating efficiencies in the built world can be unlocked through the power of our spatial data platform. Our platform and data solutions have universal applicability across industries and building categories, giving Matterport a significant advantage as we can address the entirety of this large market opportunity and increase the value of what we believe to be the largest asset class in the world.\n",
    "With a demonstrated track record of delivering value to our subscribers, our offerings include software subscription, data licensing, services and product hardware. As of December 31, 2022, our subscriber base included over 24% of Fortune 1000 companies, with less than 10% of our total revenue generated from our top 10 subscribers. We expect more than 80% of our revenue to come from our software subscription and data license solutions by 2025. Our innovative 3D capture products, the Pro2 and Pro3 Cameras, have played an integral part in shaping the 3D building and property visualization ecosystem. The Pro2 and Pro3 Cameras have driven adoption of our solutions and have generated the unique high-quality and scaled data set that has enabled Cortex, our proprietary AI software engine, to become the pioneering engine for digital twin creation. With this data advantage initially spurred by the Pro2 Camera, we have developed a capture device agnostic platform that scales and can generate new building and property insights for our subscribers across industries and geographies.\n",
    "We have recently experienced rapid growth. Our subscribers have grown approximately 49-fold from December 31, 2018 to December 31, 2022. Our revenue increased by approximately 22% to $136.1 million for the year ended December 31, 2022, from approximately $111.2 million for the year ended December 31, 2021. Our gross profit decreased by $8.1 million or 14%, to $51.8 million for the year ended December 31, 2022, from $60.0 million for the year ended December 31, 2021, primarily attributable to certain disruptive and incremental costs due to the global supply chain constraints in fiscal year 2022. Our ability to retain and grow the subscription revenue generated by our existing subscribers is an important measure of the health of our business and our future growth prospects. We track our performance in this area by measuring our net dollar expansion rate from the same set of customers across comparable periods. Our net dollar expansion rate of 103% for the three months ended December 31, 2022 demonstrates the stickiness and growth potential of our platform.\n",
    "Our Industry and Market Opportunity\n",
    "Today, the vast majority of buildings and spaces remain undigitized. We estimate our current serviceable addressable market includes approximately 1.3 billion spaces worldwide, primarily from the real estate and travel and hospitality sectors. With approximately 9.2 million spaces under management as of December 31, 2022, we are continuing to penetrate the global building stock and expand our footprint across various end markets, including residential and commercial real estate, facilities management, retail, AEC, insurance and repair, and travel and hospitality. We estimate our total addressable market to be more than 4 billion buildings and 20 billion spaces globally, yielding a more than $240 billion market opportunity. We believe that as Matterport’s unique spatial data library and property data services continue to grow, this opportunity could increase to more than $1 trillion based on the size of the building stock and the untapped value creation available to buildings worldwide. The constraints created by the COVID-19 pandemic have only reinforced and accelerated the importance of our scaled 3D capture solution that we have developed for diverse industries and markets over the past decade.\n",
    "\n",
    "Our Spatial Data Platform\n",
    "Overview\n",
    "Our technology platform uses spatial data collected from a wide variety of digital capture devices to transform physical buildings and spaces into dimensionally accurate, photorealistic digital twins that provide our subscribers access to previously unavailable building information and insights.\n",
    "As a first mover in this massive market for nearly a decade, we have developed and scaled our industry-leading 3D reconstruction technology powered by Cortex, our proprietary AI-driven software engine that uses machine learning to recreate a photorealistic, 3D virtual representation of an entire building structure, including contents, equipment and furnishings. The finished product is a detailed and dynamic replication of the physical space that can be explored, analyzed and customized from a web browser on any device, including smartphones. The power to manage even large-scale commercial buildings is in the palm of each subscriber’s hands, made possible by our advanced technology and breakthrough innovations across our entire spatial data technology stack.\n",
    "Key elements of our spatial data platform include:\n",
    "•Bringing offline buildings online. Traditionally, our customers needed to conduct in-person site visits to understand and assess their buildings and spaces. While photographs and floor plans can be helpful, these forms of two-dimensional (“2D”) representation have limited information and tend to be static and rigid, and thus lack the interactive element critical to a holistic understanding of each building and space. With the AI-powered capabilities of Cortex, our proprietary AI software, representation of physical objects is no longer confined to static 2D images and physical visits can be eliminated. Cortex helps to move the buildings and spaces from offline to online and makes them accessible to our customers in real-time and on demand from anywhere. After subscribers scan their buildings, our visualization algorithms accurately infer spatial positions and depths from flat, 2D imagery captured through the scans and transform them into high- fidelity and precise digital twin models. This creates a fully automated image processing pipeline to ensure that each digital twin is of professional grade image quality.\n",
    "•Driven by spatial data. We are a data-driven company. Each incremental capture of a space grows the richness and depth of our spatial data library. Spatial data represents the unique and idiosyncratic details that underlie and compose the buildings and spaces in the human- made environment. Cortex uses the breadth of the billions of data points we have accumulated over the years to improve the 3D accuracy of our digital twins. We help our subscribers pinpoint the height, location and other characteristics of objects in their digital twin. Our sophisticated algorithms also deliver significant commercial value to our subscribers by generating data-based insights that allow them to confidently make assessments and decisions about their properties. For instance, property developers can assess the amount of natural heat and daylight coming from specific windows, retailers can ensure each store layout is up to the same level of code and brand requirements, and factories can insure machinery layouts meet specifications and location guidelines. With approximately 9.2 million spaces under management as of December 31, 2022, our spatial data library is the clearinghouse for information about the built world.\n",
    "•Powered by AI and ML. Artificial intelligence and machine learning technologies effectively utilize spatial data to create a robust virtual experience that is dynamic, realistic, interactive, informative and permits multiple viewing angles. AI and ML also make costly cameras unnecessary for everyday scans—subscribers can now scan their spaces by simply tapping a button on their smartphones. As a result, Matterport is a device agnostic platform, helping us more rapidly scale and drive towards our mission of digitizing and indexing the built world.\n",
    "Our value proposition to subscribers is designed to serve the entirety of the digital building lifecycle, from design and build to maintenance and operations, promotion, sale, lease, insure, repair, restore, secure and finance. As a result, we believe we are uniquely positioned to grow our revenue with our subscribers as we help them to discover opportunities to drive short- and long-term return on investment by taking their buildings and spaces from offline to online across their portfolios of properties.\n",
    "Ubiquitous Capture\n",
    "Matterport has become the standard for 3D space capture. Our technology platform empowers subscribers worldwide to quickly, easily and accurately digitize, customize and manage interactive and dimensionally accurate digital twins of their buildings and spaces.\n",
    "The Matterport platform is designed to work with a wide range of LiDAR, spherical, 3D and 360 cameras, as well as smartphones, to suit the capture needs of all of our subscribers. This provides the flexibility to capture a space of any size, scale, and complexity, at anytime and anywhere.\n",
    "•Matterport Pro3 is our newest 3D camera that scans properties faster than earlier versions to help accelerate project completion. Pro3 provides the highest accuracy scans of both indoor and outdoor spaces and is designed for speed, fidelity, versatility and accuracy. Capturing 3D data up to 100 meters away at less than 20 seconds per sweep, Pro3’s ultra-fast, high-precision LiDAR sensor can run for hours and takes millions of measurements in any conditions.\n",
    "•Matterport Pro2 is our proprietary 3D camera that has been used to capture millions of spaces around the world with a high degree of fidelity, precision, speed and simplicity. Capable of capturing buildings more than 500,000 square feet in size, it has become the camera of choice for many residential, commercial, industrial and large-scale properties.\n",
    "•360 Cameras. Matterport supports a selection of 360 cameras available in the market. These affordable, pocket sized devices deliver precision captures with high fidelity and are appropriate for capturing smaller homes, condos, short-term rentals, apartments, and more. The spherical lens image capture technology of these devices gives Cortex robust, detailed image data to transform panoramas into our industry-leading digital twins.\n",
    "•LEICA BLK360. Through our partnership with Leica, our 3D reconstruction technology and our AI powered software engine, Cortex, transform this powerful LiDAR camera into an ultra-precise capture device for creating Matterport digital twins. It is the solution of choice for AEC professionals when exacting precision is required.\n",
    "•Smartphone Capture. Our capture apps are commercially available for both iOS and Android. Matterport’s smartphone capture solution has democratized 3D capture, making it easy and accessible for anyone to digitize buildings and spaces with a recent iPhone device since the initial introduction of Matterport for iPhone in May 2020. In April 2021, we announced the official release of the Android Capture app, giving Android users the ability to quickly and easily capture buildings and spaces in immersive 3D. In February 2022, we launched Matterport Axis, a motorized mount that holds a smartphone and can be used with the Matterport Capture app to capture 3D digital twins of any physical space with increased speed, precision, and consistency.\n",
    "Cortex and 3D Reconstruction (the Matterport Digital Twin)\n",
    "With a spatial data library, as of December 31, 2022, of approximately 9.2 million spaces under management, representing approximately 28 billion captured square feet of space, we use our advanced ML and DL technologies to algorithmically transform the spatial data we capture into an accurate 3D digital reproduction of any physical space. This intelligent, automated 3D reconstruction is made possible by Cortex, our AI-powered software engine that includes a deep learning neural network that uses our spatial data library to understand how a building or space is divided into floors and rooms, where the doorways and openings are located, and what types of rooms are present, such that those forms are compiled and aligned with dimensional accuracy into a dynamic, photorealistic digital twin. Other components of Cortex include AI-powered computer vision technologies to identify and classify the contents inside a building or space, and object recognition technologies to identify and segment everything from furnishings and equipment to doors, windows, light fixtures, fire suppression sprinklers and fire escapes. Our highly scalable artificial intelligence platform enables our subscribers to tap into powerful, enhanced building data and insights at the click of a button.\n",
    "\n",
    "The Science Behind the Matterport Digital Twin: Cortex AI Highlights\n",
    "Matterport Runs on Cortex\n",
    "Cortex is our AI-powered software engine that includes a precision deep learning neural network to create digital twins of any building or space. Developed using our proprietary spatial data captured with our Pro2 and Pro3 cameras, Cortex delivers a high degree of precision and accuracy while enabling 3D capture using everyday devices.\n",
    "Generic neural networks struggle with 3D reconstruction of the real world. Matterport-optimized networks deliver more accurate and robust results. More than just raw training data, Matterport’s datasets allow us to develop new neural network architectures and evaluate them against user behavior and real-world data in millions of situations.\n",
    "•Deep learning: Connecting and optimizing the detailed neural network data architecture of each space is key to creating robust, highly accurate 3D digital twins. Cortex evaluates and optimizes each 3D model against Matterport’s rich spatial data aggregated from millions of buildings and spaces and the human annotations of those data provided by tens of thousands of subscribers worldwide. Cortex’s evaluative abilities and its data-driven optimization of 3D reconstruction yield consistent, high-precision results across a wide array of building configurations, spaces and environments.\n",
    "•Dynamic 3D reconstruction: Creating precise 3D spatial data at scale from 2D visuals and static images requires a combination of photorealistic, detailed data from multiple viewpoints and millions of spaces that train and optimize Cortex’s neural network and learning capabilities for improved 3D reconstruction of any space. Cortex’s capabilities combined with real-time spatial alignment algorithms in our 3D capture technology create an intuitive “preview” of any work in progress, allowing subscribers to work with their content interactively and in real-time.\n",
    "•Computer vision: Cortex enables a suite of powerful features to enhance the value of digital twins. These include automatic measurements for rooms or objects in a room, automatic 2D-from-3D high-definition photo gallery creation, auto face blurring for privacy protection, custom videos, walkthroughs, auto room labeling and object recognition.\n",
    "•Advanced image processing: Matterport’s computational photography algorithms create a fully automated image processing pipeline to help ensure that each digital twin is of professional grade image quality. Our patented technology makes 3D capture as simple as pressing a single button. Matterport’s software and technology manage the remaining steps, including white balance and camera-specific color correction, high dynamic range tone mapping, de-noising, haze removal, sharpening, saturation and other adjustments to improve image quality.\n",
    "Spatial Data and AI-Powered Insights\n",
    "Every Matterport digital twin contains extensive information about a building, room or physical space. The data uses our AI-powered Cortex engine. In addition to the Matterport digital twin itself, our spatial data consists of precision building geometry and structural detail, building contents, fixtures and condition, along with high-definition imagery and photorealistic detail from many vantage points in a space. Cortex employs a technique we call deep spatial indexing. Deep spatial indexing uses artificial intelligence, computer vision and deep learning to identify and convey important details about each space, its structure and its contents with precision and fidelity. We have created a robust spatial data standard that enables Matterport subscribers to harness an interoperable digital system of record for any building.\n",
    "In addition to creating a highly interactive digital experience for subscribers through the construction of digital twins, we ask ourselves two questions for every subscriber: (1) what is important about their building or physical space and (2) what learnings and insights can we deliver for this space? Our AI-powered Cortex engine helps us answer these questions using our spatial data library to provide aggregated property trends and operational and valuation insights. Moreover, as the Matterport platform ecosystem continues to expand, our subscribers, partners and other third-party developers can bring their own tools to further the breadth and depth of insights they can harvest from our rich spatial data layer.\n",
    "Extensible Platform Ecosystem\n",
    "Matterport offers the largest and most accurate library of spatial data in the world, with, as of December 31, 2022, approximately 9.2 million spaces under management and approximately 28 billion captured square feet. The versatility of our spatial data platform and extensive enterprise software development kit and application programming interfaces (“APIs”) has allowed us to develop a robust global ecosystem of channels and partners that extend the Matterport value proposition by geography and vertical market. We intend to continue to deploy a broad set of workflow integrations with our partners and their subscribers to promote an integrated Matterport solution across our target markets. We are also developing a third-party software marketplace to extend the power of our spatial data platform with easy-to-deploy and easy-to-access Matterport software add-ons. The marketplace enables developers to build new applications and spatial data mining tools, enhance the Matterport 3D experience, and create new productivity and property management tools that supplement our core offerings. These value-added capabilities created by third-party developers enable a scalable new revenue stream, with Matterport sharing the subscription and services revenue from each add-on that is deployed to subscribers through the online marketplace. The network effects of our platform ecosystem contributes to the growth of our business, and we believe that it will continue to bolster future growth by enhancing subscriber stickiness and user engagement.\n",
    "Examples of Matterport add-ons and extensions include:\n",
    "•Add-ons: Encircle (easy-to-use field documentation tools for faster claims processing); WP Matterport Shortcode (free Wordpress plugin that allows Matterport to be embedded quickly and easily with a Matterport shortcode), WP3D Models (WordPress + Matterport integration plugin); Rela (all-in-one marketing solution for listings); CAPTUR3D (all-in-one Content Management System that extends value to Matterport digital twins); Private Model Emded (feature that allows enterprises to privately share digital twins with a large group of employees on the corporate network without requiring additional user licenses); Views (new workgroup collaboration framework to enable groups and large organizations to create separate, permissions-based workflows to manage different tasks with different teams); and Guided Tours and Tags (tool to elevate the visitor experience by creating directed virtual tours of any commercial or residential space tailored to the interests of their visitors). We unveiled our private beta integration with Amazon Web Services (AWS) IoT TwinMaker to enable enterprise customers to seamlessly connect IoT data into visually immersive and dimensionally accurate Matterport digital twin.\n",
    "•Services: Matterport ADA Compliant Digital Twin (solution to provide American Disability Act compliant digital twins) and Enterprise Cloud Software Platform (reimagined cloud software platform for the enterprise that creates, publishes, and manages digital twins of buildings and spaces of any size of shape, indoors or outdoors).\n",
    "Our Competitive Strengths\n",
    "We believe that we have a number of competitive strengths that will enable our market leadership to grow. Our competitive strengths include:\n",
    "•Breadth and depth of the Matterport platform. Our core strength is our all-in-one spatial data platform with broad reach across diverse verticals and geographies such as capture to processing to industries without customization. With the ability to integrate seamlessly with various enterprise systems, our platform delivers value across the property lifecycle for diverse end markets, including real estate, AEC, travel and hospitality, repair and insurance, and industrial and facilities. As of December 31, 2022, our global reach extended to subscribers in more than 170 countries, including over 24% of Fortune 1000 companies.\n",
    "•Market leadership and first-mover advantage. Matterport defined the category of digitizing and datafying the built world almost a decade ago, and we have become the global leader in the category. As of December 31, 2022, we had over 701,000 subscribers on our platform and approximately 9.2 million spaces under management. Our leadership is primarily driven by the fact that we were the first mover in digital twin creation. As a result of our first mover advantage, we have amassed a deep and rich library of spatial data that continues to compound and enhance our leadership position.\n",
    "•Significant network effect. With each new capture and piece of data added to our platform, the richness of our dataset and the depth of insights from our spaces under management grow. In addition, the combination of our ability to turn data into insights with incremental data from new data captures by our subscribers enables Matterport to develop features for subscribers to our platform. We were a first mover in building a spatial data library for the built world, and our leadership in gathering and deriving insights from data continues to compound and the relevance of those insights attracts more new subscribers.\n",
    "•Massive spatial data library as the raw material for valuable property insights. The scale of our spatial data library is a significant advantage in deriving insights for our subscribers. Our spatial data library serves as vital ground truth for Cortex, enabling Matterport to create powerful 3D digital twins using a wide range of camera technology, including low-cost digital and smartphone cameras. As of December 31, 2022, our data came from approximately 9.2 million spaces under management and approximately 28 billion captured square feet. As a result, we have taken property insights and analytics to new levels, benefiting subscribers across various industries. For example, facilities managers significantly reduce the time needed to create building layouts, leading to a significant decrease in the cost of site surveying and as-built modeling. AEC subscribers use the analytics of each as-built space to streamline documentation and collaborate with ease.\n",
    "•Global reach and scale. We are focused on continuing to expand our AI-powered spatial data platform worldwide. We have a significant presence in North America, Europe and Asia, with leadership teams and a go-to-market infrastructure in each of these regions. We have offices in London, Singapore and several across the United States, and we are accelerating our international expansion. As of December 31, 2022, we had over 701,000 subscribers in more than 170 countries. We believe that the geography-agnostic nature of our spatial data platform is a significant advantage as we continue to grow internationally.\n",
    "•Broad patent portfolio supporting 10 years of R&D and innovation. As of December 31, 2022, we had 54 issued and 37 pending patent applications. Our success is based on almost 10 years of focus on innovation. Innovation has been at the center of Matterport, and we will continue to prioritize our investments in R&D to further our market leading position.\n",
    "•Superior capture technology. Matterport’s capture technology platform is a software framework that enables support for a wide variety of capture devices required to create a Matterport digital twin of a building or space.\n",
    "This includes support for LiDAR cameras, 360 cameras, smartphones, Matterport Axis and the Matterport Pro2 and Pro3 cameras. The Pro2 camera was foundational to our spatial data advantage, and we have expanded that advantage with an array of Matterport-enabled third-party capture devices. In August 2022, we launched and began shipment of our Pro3 Camera along with major updates to our industry-leading digital twin cloud platform. The Matterport Pro3 Camera is an advanced 3D capture device, which includes faster boot time, swappable batteries, and a lighter design. The Pro3 camera can perform both indoors and outdoors and is designed for speed, fidelity, versatility and accuracy. Along with our Pro2 Camera, we expect that future sales of our Pro3 Camera will continue to drive increased adoption of our solutions. Matterport is democratizing the 3D capture experience, making high-fidelity and high-accuracy 3D digital twins readily available for any building type and any subscriber need in the property life cycle. While there are other 3D capture solution providers, very few can produce true, dimensionally accurate 3D results, and fewer still can automatically create a final product in photorealistic 3D, and at global scale. This expansive capture technology offering would not be possible without our rich spatial data library available to train the AI-powered Cortex engine to automatically generate accurate digital twins from photos captured with a smartphone or 360 camera.\n",
    "</document>\n",
    "Assistant: \"\"\"\n",
    "response = completion(\n",
    "    temperature=0.0,\n",
    "    model=\"mistral/mistral-large-latest\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"You are a very careful accountant.\"},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f0be7-3c12-4f78-9439-67ae5a52781b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
